{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_xvJXPhCkMA"
   },
   "source": [
    "# Título  Variables con RF\n",
    "## Autor: Jose Chelquer\n",
    "## Fecha de última modificación: 21/11/2024\n",
    "## Descripción:\n",
    "Agrega features corriendo RF con lgbm.\n",
    "Agrega variables por cada hoja del lgbm, indicando si la observación está o no ahi.\n",
    "\n",
    "Para entrenar y predecir, no usa las variables relacionadas con foto_mes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRTSvXdLHkpB"
   },
   "source": [
    "## Parámetros\n",
    "\n",
    "< Descripción de cada uno de los parámetros que utiliza el job >\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yMU00Fl7IIfm"
   },
   "outputs": [],
   "source": [
    "# vm o local?\n",
    "vm=True\n",
    "if vm:\n",
    "  usar_gdrive=False\n",
    "else:\n",
    "  usar_gdrive=True      #se va a usar google dirve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KTHNlNBrPhX-"
   },
   "outputs": [],
   "source": [
    "semillas = [17,19,23,29,31]\n",
    "ganancia_acierto=273000\n",
    "costo_estimulo=7000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "61j56HBIKFeR"
   },
   "outputs": [],
   "source": [
    "# datos de entrenamiento\n",
    "if vm:\n",
    "  meses_entrenamiento=[202010, 202011, 202012]\n",
    "  submuestrear=False\n",
    "else:\n",
    "  meses_entrenamiento=[202101, 202102, 202103]\n",
    "  submuestrear=False\n",
    "\n",
    "grabar_importancias=False          # Se puede pedir que grabe las importancias de variables como resultado secundario\n",
    "importancias_file='importancias_rf.csv.gz'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sH5VivJSIM42"
   },
   "source": [
    "## Input\n",
    "\n",
    "< Archivos de datos (parquet.gz) con sus paths que van a consumirse por el job>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MEk4Fj7VIv7g"
   },
   "outputs": [],
   "source": [
    "# El script se adapta a archivos .parquet o .parquet.gz\n",
    "if vm:\n",
    "  dataset_path = '/home/jose/buckets/b1/datasets/'\n",
    "  dataset_file='k2_aumentada.parquet.gz'\n",
    "else:\n",
    "  dataset_path='/content/drive/MyDrive/Data Science y similares/Maestría Data Mining Exactas/dmeyf/dmeyf2024/datasets/'\n",
    "  dataset_file='k2_sample_parquet.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQ6MUhENI0Ya"
   },
   "source": [
    "## Output\n",
    "\n",
    "< Archivos, bases de datos, modelos que va a generar el job>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZT3kxlkFIv4p"
   },
   "outputs": [],
   "source": [
    "# el script se adapta a datasets .parquet o .gz\n",
    "if vm:\n",
    "  output_file='k2_aumentada_conRF.parquet.gz'\n",
    "else:\n",
    "  output_file='k2_sample.conRF.parquet.gz'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VrRYsZMowzEl"
   },
   "source": [
    "## Procesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVe0GO1IJHtI"
   },
   "source": [
    "### Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3699,
     "status": "ok",
     "timestamp": 1731377015530,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "O2VG2xS_Ivq3",
    "outputId": "049bf30e-e1c8-45c9-8777-00ae64adadfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna==4.0 in /home/jose/.venv/lib/python3.12/site-packages (4.0.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/jose/.venv/lib/python3.12/site-packages (from optuna==4.0) (1.13.2)\n",
      "Requirement already satisfied: colorlog in /home/jose/.venv/lib/python3.12/site-packages (from optuna==4.0) (6.8.2)\n",
      "Requirement already satisfied: numpy in /home/jose/.venv/lib/python3.12/site-packages (from optuna==4.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jose/.venv/lib/python3.12/site-packages (from optuna==4.0) (24.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/jose/.venv/lib/python3.12/site-packages (from optuna==4.0) (2.0.35)\n",
      "Requirement already satisfied: tqdm in /home/jose/.venv/lib/python3.12/site-packages (from optuna==4.0) (4.66.5)\n",
      "Requirement already satisfied: PyYAML in /home/jose/.venv/lib/python3.12/site-packages (from optuna==4.0) (6.0.2)\n",
      "Requirement already satisfied: Mako in /home/jose/.venv/lib/python3.12/site-packages (from alembic>=1.5.0->optuna==4.0) (1.3.5)\n",
      "Requirement already satisfied: typing-extensions>=4 in /home/jose/.venv/lib/python3.12/site-packages (from alembic>=1.5.0->optuna==4.0) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/jose/.venv/lib/python3.12/site-packages (from sqlalchemy>=1.3.0->optuna==4.0) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/jose/.venv/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna==4.0) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install optuna==3.6.1\n",
    "%pip install optuna==4.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LM2kY_WJj15"
   },
   "source": [
    "## Código del proceso\n",
    "\n",
    "< Todo el código a partir de aquí debe poder ejecutarse sin necesidad de parametrizar nada>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0X0atYk2Bqf"
   },
   "source": [
    "Instalamos, cargamos y seteamos el entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "sc7PN8Rw2Xz-"
   },
   "outputs": [],
   "source": [
    "#%pip install scikit-learn==1.3.2\n",
    "#%pip install seaborn==0.13.1\n",
    "#%pip install numpy==1.26.4\n",
    "#%pip install matplotlib==3.7.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vteA4xbLOv9m"
   },
   "source": [
    "## Gdrive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1918,
     "status": "ok",
     "timestamp": 1731377017442,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "SocMOWB6Ofpw",
    "outputId": "0f3af543-f708-446c-fc9d-279b235d53b3"
   },
   "outputs": [],
   "source": [
    "if usar_gdrive:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yVsD15O85ms"
   },
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/jose/.venv/lib/python3.12/site-packages (24.3.1)\n",
      "Requirement already satisfied: lightgbm in /home/jose/.venv/lib/python3.12/site-packages (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/jose/.venv/lib/python3.12/site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in /home/jose/.venv/lib/python3.12/site-packages (from lightgbm) (1.14.1)\n",
      "Requirement already satisfied: dask[dataframe] in /home/jose/.venv/lib/python3.12/site-packages (2024.9.0)\n",
      "Requirement already satisfied: click>=8.1 in /home/jose/.venv/lib/python3.12/site-packages (from dask[dataframe]) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /home/jose/.venv/lib/python3.12/site-packages (from dask[dataframe]) (3.0.0)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /home/jose/.venv/lib/python3.12/site-packages (from dask[dataframe]) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jose/.venv/lib/python3.12/site-packages (from dask[dataframe]) (24.1)\n",
      "Requirement already satisfied: partd>=1.4.0 in /home/jose/.venv/lib/python3.12/site-packages (from dask[dataframe]) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/jose/.venv/lib/python3.12/site-packages (from dask[dataframe]) (6.0.2)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /home/jose/.venv/lib/python3.12/site-packages (from dask[dataframe]) (0.12.1)\n",
      "Requirement already satisfied: pandas>=2.0 in /home/jose/.venv/lib/python3.12/site-packages (from dask[dataframe]) (2.2.3)\n",
      "Requirement already satisfied: dask-expr<1.2,>=1.1 in /home/jose/.venv/lib/python3.12/site-packages (from dask[dataframe]) (1.1.14)\n",
      "Requirement already satisfied: pyarrow>=14.0.1 in /home/jose/.venv/lib/python3.12/site-packages (from dask-expr<1.2,>=1.1->dask[dataframe]) (17.0.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/jose/.venv/lib/python3.12/site-packages (from pandas>=2.0->dask[dataframe]) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/jose/.venv/lib/python3.12/site-packages (from pandas>=2.0->dask[dataframe]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jose/.venv/lib/python3.12/site-packages (from pandas>=2.0->dask[dataframe]) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/jose/.venv/lib/python3.12/site-packages (from pandas>=2.0->dask[dataframe]) (2024.1)\n",
      "Requirement already satisfied: locket in /home/jose/.venv/lib/python3.12/site-packages (from partd>=1.4.0->dask[dataframe]) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/jose/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=2.0->dask[dataframe]) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --upgrade lightgbm\n",
    "!pip install dask[dataframe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "x0IutZ5v4Pn5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import optuna\n",
    "from optuna.storages import JournalStorage\n",
    "from optuna.storages.journal import JournalFileBackend\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances, plot_slice, plot_contour\n",
    "\n",
    "from time import time\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import lightgbm as lgb\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1M-SwdFOykc"
   },
   "source": [
    "## Leer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "IbyPo4Dk4Mdh"
   },
   "outputs": [],
   "source": [
    "data_original = pd.read_parquet(os.path.join(dataset_path, dataset_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1731377029140,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "yK_UpTmCUmtv",
    "outputId": "ed4f9efa-529c-46ee-c617-b608a72b2d4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contabilización de la base Datos Leídos\n",
      "\n",
      "\n",
      "Shape: (375309, 1080)\n",
      "\n",
      "\\ por mes: \n",
      "foto_mes\n",
      "202108    165442\n",
      "202104     18363\n",
      "202105     18352\n",
      "202106     18271\n",
      "202103     18169\n",
      "202102     17886\n",
      "202101     17481\n",
      "202012     17307\n",
      "202011     17097\n",
      "202010     16921\n",
      "202009     16771\n",
      "202007     16629\n",
      "202008     16620\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Filas por mes y clase: \n",
      "clase_ternaria  BAJA+1  BAJA+2  CONTINUA\n",
      "foto_mes                                \n",
      "202007             627     542     15460\n",
      "202008             544     472     15604\n",
      "202009             474     564     15733\n",
      "202010             565     488     15868\n",
      "202011             490     646     15961\n",
      "202012             649     634     16024\n",
      "202101             635     785     16061\n",
      "202102             785    1017     16084\n",
      "202103            1020     981     16168\n",
      "202104             982    1189     16192\n",
      "202105            1189     911     16252\n",
      "202106             908    1074     16289\n",
      "202108          165442       0         0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\ '\n",
      "/tmp/ipykernel_6873/3529553369.py:4: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  print (f\"\\ por mes: \\n{df['foto_mes'].value_counts()}\\n\")\n"
     ]
    }
   ],
   "source": [
    "def contabilizar(df, descripción):\n",
    "  print (f'\\nContabilización de la base {descripción}\\n')\n",
    "  print (f'\\nShape: {df.shape}\\n')\n",
    "  print (f\"\\ por mes: \\n{df['foto_mes'].value_counts()}\\n\")\n",
    "  print (f\"\\nFilas por mes y clase: \\n{pd.crosstab(df['foto_mes'], df['clase_ternaria'])}\\n\")\n",
    "contabilizar(data_original, 'Datos Leídos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNfgftZTBfx1"
   },
   "source": [
    "## Recodificar a clase binaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0kIbkfo2Bekp"
   },
   "outputs": [],
   "source": [
    "data_original['clase_peso'] = 1.0\n",
    "\n",
    "data_original.loc[data_original['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "data_original.loc[data_original['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "954BAsluBteG"
   },
   "outputs": [],
   "source": [
    "data_original['clase_binaria1'] = 0\n",
    "data_original['clase_binaria2'] = 0\n",
    "data_original['clase_binaria1'] = np.where(data_original['clase_ternaria'] == 'BAJA+2', 1, 0)\n",
    "data_original['clase_binaria2'] = np.where(data_original['clase_ternaria'] == 'CONTINUA', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1731377029640,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "UnYMoA1l4jJ3",
    "outputId": "96e56757-79c1-453b-9056-102989301b48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contabilización de la base Datos para hacer RF\n",
      "\n",
      "\n",
      "Shape: (51325, 1083)\n",
      "\n",
      "\\ por mes: \n",
      "foto_mes\n",
      "202012    17307\n",
      "202011    17097\n",
      "202010    16921\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Filas por mes y clase: \n",
      "clase_ternaria  BAJA+1  BAJA+2  CONTINUA\n",
      "foto_mes                                \n",
      "202010             565     488     15868\n",
      "202011             490     646     15961\n",
      "202012             649     634     16024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Elige los meses y balancea\n",
    "if meses_entrenamiento:\n",
    "  data = data_original[data_original['foto_mes'].isin(meses_entrenamiento)]\n",
    "else:\n",
    "  data = data_original.copy()\n",
    "# Elimina las variables asociadas a foto_mes\n",
    "cols_fotos=[col for col in data.columns if 'foto_mes_lag' in col]\n",
    "data=data.drop(columns=cols_fotos)\n",
    "\n",
    "#Submuestrear para balancear\n",
    "if submuestrear:\n",
    "  # Separar las clases\n",
    "  data_0 = data[data['clase_binaria2'] == 0]\n",
    "  data_1 = data[data['clase_binaria2'] == 1]\n",
    "  n_samples=min(len(data_0), len(data_1))\n",
    "\n",
    "  # Hacer un submuestreo de la clase mayoritaria\n",
    "  data_0 = resample(data_0,\n",
    "                    replace=False,  # No reemplace\n",
    "                    n_samples=n_samples,  # Igualar tamaño de la clase minoritaria\n",
    "                    random_state=123)  # Para reproducibilidad\n",
    "  data_1 = resample(data_1,\n",
    "                    replace=False,  # No reemplace\n",
    "                    n_samples=n_samples,  # Igualar tamaño de la clase minoritaria\n",
    "                    random_state=123)  # Para reproducibilidad\n",
    "\n",
    "  # Combinar clases balanceadas\n",
    "  data_balanced = pd.concat([data_0, data_1])\n",
    "\n",
    "  # Mezclar el DataFrame resultante\n",
    "  data = data_balanced.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "contabilizar (data, 'Datos para hacer RF')\n",
    "\n",
    "y = data['clase_binaria2']\n",
    "X=data.drop(['clase_ternaria','clase_peso', 'clase_binaria1','clase_binaria2'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKqHx1ZMO2Iu"
   },
   "source": [
    "## Función ganancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "TWHFFm431krP"
   },
   "outputs": [],
   "source": [
    "def rf_gan_eval(y_pred, data):\n",
    "    clase_ternaria = data.get_clase_ternaria()\n",
    "    # Diferencia si eran BAJA+1 o BAJA+2\n",
    "    ganancia = np.where(clase_ternaria == 'BAJA+2', ganancia_acierto, 0) - np.where(clase_ternaria !='BAJA+2', costo_estimulo, 0)\n",
    "    #Ordena ganancia según los índices ordenados de y_pred de mayor a menor\n",
    "    ganancia = ganancia[np.argsort(y_pred)[::-1]] #: desde todo : hasta todo :-1 step hacia atrás\n",
    "    # Ganancias acumuladas so far\n",
    "    ganancia = np.cumsum(ganancia)\n",
    "\n",
    "    return 'gan_eval', np.max(ganancia) , True\n",
    "\n",
    "def ganancia_prob(y_hat, y, prop=1, class_index=1, threshold=0.025):\n",
    "  @np.vectorize\n",
    "  def ganancia_row(predicted, actual, threshold=0.025):\n",
    "    return  (predicted >= threshold) * (ganancia_acierto if actual == \"BAJA+2\" else -costo_estimulo)\n",
    "\n",
    "  return ganancia_row(y_hat[:,class_index], y).sum() / prop\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQ0ZGmGAK89b"
   },
   "source": [
    "## Imputar NANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 301,
     "status": "ok",
     "timestamp": 1731377029927,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "Ge2QADE-ZYiA",
    "outputId": "c097eb1c-55c5-4883-ce6b-79b32f4c5d83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cant de Nans:numero_de_cliente                     0\n",
      "foto_mes                              0\n",
      "active_quarter                        0\n",
      "cliente_vip                           0\n",
      "internet                              0\n",
      "                                  ...  \n",
      "Tarjeta_mpagosdolares_n10_lag2    48082\n",
      "Tarjeta_mconsumototal_n10_lag1    32635\n",
      "Tarjeta_mconsumototal_n10_lag2    48082\n",
      "Tarjeta_mpagominimo_n10_lag1      32635\n",
      "Tarjeta_mpagominimo_n10_lag2      48082\n",
      "Length: 1079, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (f'Cant de Nans:{X.isnull().sum()}')\n",
    "#imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "#if X.isnull().values.any():\n",
    "#  X = imp_mean.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6qHrBQeLCej"
   },
   "source": [
    "## Ajustar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1854,
     "status": "ok",
     "timestamp": 1731377031779,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "ExNBUAIFIjdW",
    "outputId": "fa5e29bf-6722-48c2-a34d-0748268c8af0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fiteando\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin del fit\n"
     ]
    }
   ],
   "source": [
    "# Cambio\n",
    "# Fitear el modelo con X e y\n",
    "model = lgb.LGBMClassifier(\n",
    "    # parametros que se pueden cambiar\n",
    "    num_iterations = 20,\n",
    "    num_leaves  = 16,\n",
    "    min_data_in_leaf = 1000,\n",
    "    feature_fraction_bynode  = 0.2,\n",
    "\n",
    "    # para que LightGBM emule Random Forest\n",
    "    boosting_type = \"rf\",\n",
    "    bagging_fraction = ( 1.0 - 1.0/exp(1.0) ),\n",
    "    bagging_freq = 1,\n",
    "    feature_fraction = 1,\n",
    "\n",
    "    # genericos de LightGBM\n",
    "    max_bin = 31,\n",
    "    objective = \"binary\",\n",
    "    first_metric_only = True,\n",
    "    boost_from_average = True,\n",
    "    feature_pre_filter = False,\n",
    "    force_row_wise = True,\n",
    "    verbosity = -100,\n",
    "    max_depth = -1,\n",
    "    min_gain_to_split = 0.0,\n",
    "    min_sum_hessian_in_leaf = 0.001,\n",
    "    lambda_l1 = 0.0,\n",
    "    lambda_l2 = 0.0,\n",
    "\n",
    "    pos_bagging_fraction = 1.0,\n",
    "    neg_bagging_fraction = 1.0,\n",
    "    is_unbalance = True,\n",
    "    scale_pos_weight = 1.0,\n",
    "\n",
    "    drop_rate = 0.1,\n",
    "    max_drop = 50,\n",
    "    skip_drop = 0.5,\n",
    "\n",
    "    extra_trees = False\n",
    "  )\n",
    "print(\"Fiteando\")\n",
    "model.fit(X, y)\n",
    "print(\"Fin del fit\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1731377031780,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "jtbfCOrONos4",
    "outputId": "cca2d485-44b4-4839-f9d4-51b36d9c06a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      feature  importance\n",
      "211           ratio_mcomisiones_mantenimiento          19\n",
      "52                                   mpayroll          12\n",
      "201                            ratio_mpayroll          10\n",
      "212                   ratio_mcomisiones_otras          10\n",
      "107                              ctrx_quarter          10\n",
      "181                         ratio_mcomisiones          10\n",
      "274                       mpasivos_margen_n10           9\n",
      "51                               cpayroll_trx           9\n",
      "180                ratio_mrentabilidad_annual           8\n",
      "73                          ccomisiones_otras           7\n",
      "155                    ctarjeta_transacciones           7\n",
      "28                      mtarjeta_visa_consumo           7\n",
      "280                        mcuentas_saldo_n10           5\n",
      "461                             mpayroll_lag1           5\n",
      "27                ctarjeta_visa_transacciones           5\n",
      "188                ratio_mcaja_ahorro_dolares           5\n",
      "25                              mautoservicio           4\n",
      "156                          mtarjeta_consumo           4\n",
      "204  ratio_mttarjeta_visa_debitos_automaticos           4\n",
      "240                    ratio_Visa_msaldopesos           4\n"
     ]
    }
   ],
   "source": [
    "features = data.drop(['clase_ternaria','clase_peso', 'clase_binaria1','clase_binaria2'], axis=1).columns\n",
    "importances = model.feature_importances_\n",
    "feat_importances = pd.DataFrame({'feature': features, 'importance': importances})\n",
    "feat_importances = feat_importances.sort_values('importance', ascending=False)\n",
    "print(feat_importances.head(20))\n",
    "\n",
    "if grabar_importancias:\n",
    "    if importancias_file.endswith('.gz'):\n",
    "      feat_importances.to_parquet(os.path.join(dataset_path,  importancias_file), index=False, compression='gzip')\n",
    "    else:\n",
    "      feat_importances.to_parquet(os.path.join(dataset_path,  importancias_file), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqOU5mkfZdns"
   },
   "source": [
    "## Crear variables RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "nNPyQlmB-BXO"
   },
   "outputs": [],
   "source": [
    "# Ahora, con todos los datos\n",
    "data = data_original.copy()\n",
    "cols_fotos=[col for col in data.columns if 'foto_mes_lag' in col]\n",
    "data=data.drop(columns=cols_fotos)\n",
    "y_completo=data['clase_binaria2']\n",
    "X_completo=data.drop(['clase_ternaria','clase_peso', 'clase_binaria1','clase_binaria2'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1221,
     "status": "ok",
     "timestamp": 1731377033989,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "hi9ED3_bdG6Y",
    "outputId": "5ebd75f5-7938-424b-b70c-08b9fdf018cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375309, 20)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener las hojas para cada observación\n",
    "leaf_indices = model.predict(X_completo, pred_leaf=True)\n",
    "leaf_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1731377033989,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "XEGrS6kQ7If9",
    "outputId": "b328e0e1-ee81-491b-88fc-c7e52e22c7ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boosting_type': 'rf', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': None, 'num_leaves': 16, 'objective': 'binary', 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'num_iterations': 20, 'min_data_in_leaf': 1000, 'feature_fraction_bynode': 0.2, 'bagging_fraction': 0.6321205588285577, 'bagging_freq': 1, 'feature_fraction': 1, 'max_bin': 31, 'first_metric_only': True, 'boost_from_average': True, 'feature_pre_filter': False, 'force_row_wise': True, 'verbosity': -100, 'min_gain_to_split': 0.0, 'min_sum_hessian_in_leaf': 0.001, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'pos_bagging_fraction': 1.0, 'neg_bagging_fraction': 1.0, 'is_unbalance': True, 'scale_pos_weight': 1.0, 'drop_rate': 0.1, 'max_drop': 50, 'skip_drop': 0.5, 'extra_trees': False}\n"
     ]
    }
   ],
   "source": [
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7789,
     "status": "ok",
     "timestamp": 1731377041775,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "DaU4Ik_wPlMK",
    "outputId": "b2de4750-41da-4615-d425-aa9508fba432"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de leaf_dummies: (375309, 320)\n",
      "Cant de árboles: 20\n",
      "1 Agregando campo: tree_0_leaf_0\n",
      "2 Agregando campo: tree_0_leaf_1\n",
      "3 Agregando campo: tree_0_leaf_2\n",
      "4 Agregando campo: tree_0_leaf_3\n",
      "5 Agregando campo: tree_0_leaf_4\n",
      "6 Agregando campo: tree_0_leaf_5\n",
      "7 Agregando campo: tree_0_leaf_6\n",
      "8 Agregando campo: tree_0_leaf_7\n",
      "9 Agregando campo: tree_0_leaf_8\n",
      "10 Agregando campo: tree_0_leaf_9\n",
      "11 Agregando campo: tree_0_leaf_10\n",
      "12 Agregando campo: tree_0_leaf_11\n",
      "13 Agregando campo: tree_0_leaf_12\n",
      "14 Agregando campo: tree_0_leaf_13\n",
      "15 Agregando campo: tree_0_leaf_14\n",
      "16 Agregando campo: tree_0_leaf_15\n",
      "17 Agregando campo: tree_1_leaf_0\n",
      "18 Agregando campo: tree_1_leaf_1\n",
      "19 Agregando campo: tree_1_leaf_2\n",
      "20 Agregando campo: tree_1_leaf_3\n",
      "21 Agregando campo: tree_1_leaf_4\n",
      "22 Agregando campo: tree_1_leaf_5\n",
      "23 Agregando campo: tree_1_leaf_6\n",
      "24 Agregando campo: tree_1_leaf_7\n",
      "25 Agregando campo: tree_1_leaf_8\n",
      "26 Agregando campo: tree_1_leaf_9\n",
      "27 Agregando campo: tree_1_leaf_10\n",
      "28 Agregando campo: tree_1_leaf_11\n",
      "29 Agregando campo: tree_1_leaf_12\n",
      "30 Agregando campo: tree_1_leaf_13\n",
      "31 Agregando campo: tree_1_leaf_14\n",
      "32 Agregando campo: tree_1_leaf_15\n",
      "33 Agregando campo: tree_2_leaf_0\n",
      "34 Agregando campo: tree_2_leaf_1\n",
      "35 Agregando campo: tree_2_leaf_2\n",
      "36 Agregando campo: tree_2_leaf_3\n",
      "37 Agregando campo: tree_2_leaf_4\n",
      "38 Agregando campo: tree_2_leaf_5\n",
      "39 Agregando campo: tree_2_leaf_6\n",
      "40 Agregando campo: tree_2_leaf_7\n",
      "41 Agregando campo: tree_2_leaf_8\n",
      "42 Agregando campo: tree_2_leaf_9\n",
      "43 Agregando campo: tree_2_leaf_10\n",
      "44 Agregando campo: tree_2_leaf_11\n",
      "45 Agregando campo: tree_2_leaf_12\n",
      "46 Agregando campo: tree_2_leaf_13\n",
      "47 Agregando campo: tree_2_leaf_14\n",
      "48 Agregando campo: tree_2_leaf_15\n",
      "49 Agregando campo: tree_3_leaf_0\n",
      "50 Agregando campo: tree_3_leaf_1\n",
      "51 Agregando campo: tree_3_leaf_2\n",
      "52 Agregando campo: tree_3_leaf_3\n",
      "53 Agregando campo: tree_3_leaf_4\n",
      "54 Agregando campo: tree_3_leaf_5\n",
      "55 Agregando campo: tree_3_leaf_6\n",
      "56 Agregando campo: tree_3_leaf_7\n",
      "57 Agregando campo: tree_3_leaf_8\n",
      "58 Agregando campo: tree_3_leaf_9\n",
      "59 Agregando campo: tree_3_leaf_10\n",
      "60 Agregando campo: tree_3_leaf_11\n",
      "61 Agregando campo: tree_3_leaf_12\n",
      "62 Agregando campo: tree_3_leaf_13\n",
      "63 Agregando campo: tree_3_leaf_14\n",
      "64 Agregando campo: tree_3_leaf_15\n",
      "65 Agregando campo: tree_4_leaf_0\n",
      "66 Agregando campo: tree_4_leaf_1\n",
      "67 Agregando campo: tree_4_leaf_2\n",
      "68 Agregando campo: tree_4_leaf_3\n",
      "69 Agregando campo: tree_4_leaf_4\n",
      "70 Agregando campo: tree_4_leaf_5\n",
      "71 Agregando campo: tree_4_leaf_6\n",
      "72 Agregando campo: tree_4_leaf_7\n",
      "73 Agregando campo: tree_4_leaf_8\n",
      "74 Agregando campo: tree_4_leaf_9\n",
      "75 Agregando campo: tree_4_leaf_10\n",
      "76 Agregando campo: tree_4_leaf_11\n",
      "77 Agregando campo: tree_4_leaf_12\n",
      "78 Agregando campo: tree_4_leaf_13\n",
      "79 Agregando campo: tree_4_leaf_14\n",
      "80 Agregando campo: tree_4_leaf_15\n",
      "81 Agregando campo: tree_5_leaf_0\n",
      "82 Agregando campo: tree_5_leaf_1\n",
      "83 Agregando campo: tree_5_leaf_2\n",
      "84 Agregando campo: tree_5_leaf_3\n",
      "85 Agregando campo: tree_5_leaf_4\n",
      "86 Agregando campo: tree_5_leaf_5\n",
      "87 Agregando campo: tree_5_leaf_6\n",
      "88 Agregando campo: tree_5_leaf_7\n",
      "89 Agregando campo: tree_5_leaf_8\n",
      "90 Agregando campo: tree_5_leaf_9\n",
      "91 Agregando campo: tree_5_leaf_10\n",
      "92 Agregando campo: tree_5_leaf_11\n",
      "93 Agregando campo: tree_5_leaf_12\n",
      "94 Agregando campo: tree_5_leaf_13\n",
      "95 Agregando campo: tree_5_leaf_14\n",
      "96 Agregando campo: tree_5_leaf_15\n",
      "97 Agregando campo: tree_6_leaf_0\n",
      "98 Agregando campo: tree_6_leaf_1\n",
      "99 Agregando campo: tree_6_leaf_2\n",
      "100 Agregando campo: tree_6_leaf_3\n",
      "101 Agregando campo: tree_6_leaf_4\n",
      "102 Agregando campo: tree_6_leaf_5\n",
      "103 Agregando campo: tree_6_leaf_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 Agregando campo: tree_6_leaf_7\n",
      "105 Agregando campo: tree_6_leaf_8\n",
      "106 Agregando campo: tree_6_leaf_9\n",
      "107 Agregando campo: tree_6_leaf_10\n",
      "108 Agregando campo: tree_6_leaf_11\n",
      "109 Agregando campo: tree_6_leaf_12\n",
      "110 Agregando campo: tree_6_leaf_13\n",
      "111 Agregando campo: tree_6_leaf_14\n",
      "112 Agregando campo: tree_6_leaf_15\n",
      "113 Agregando campo: tree_7_leaf_0\n",
      "114 Agregando campo: tree_7_leaf_1\n",
      "115 Agregando campo: tree_7_leaf_2\n",
      "116 Agregando campo: tree_7_leaf_3\n",
      "117 Agregando campo: tree_7_leaf_4\n",
      "118 Agregando campo: tree_7_leaf_5\n",
      "119 Agregando campo: tree_7_leaf_6\n",
      "120 Agregando campo: tree_7_leaf_7\n",
      "121 Agregando campo: tree_7_leaf_8\n",
      "122 Agregando campo: tree_7_leaf_9\n",
      "123 Agregando campo: tree_7_leaf_10\n",
      "124 Agregando campo: tree_7_leaf_11\n",
      "125 Agregando campo: tree_7_leaf_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 Agregando campo: tree_7_leaf_13\n",
      "127 Agregando campo: tree_7_leaf_14\n",
      "128 Agregando campo: tree_7_leaf_15\n",
      "129 Agregando campo: tree_8_leaf_0\n",
      "130 Agregando campo: tree_8_leaf_1\n",
      "131 Agregando campo: tree_8_leaf_2\n",
      "132 Agregando campo: tree_8_leaf_3\n",
      "133 Agregando campo: tree_8_leaf_4\n",
      "134 Agregando campo: tree_8_leaf_5\n",
      "135 Agregando campo: tree_8_leaf_6\n",
      "136 Agregando campo: tree_8_leaf_7\n",
      "137 Agregando campo: tree_8_leaf_8\n",
      "138 Agregando campo: tree_8_leaf_9\n",
      "139 Agregando campo: tree_8_leaf_10\n",
      "140 Agregando campo: tree_8_leaf_11\n",
      "141 Agregando campo: tree_8_leaf_12\n",
      "142 Agregando campo: tree_8_leaf_13\n",
      "143 Agregando campo: tree_8_leaf_14\n",
      "144 Agregando campo: tree_8_leaf_15\n",
      "145 Agregando campo: tree_9_leaf_0\n",
      "146 Agregando campo: tree_9_leaf_1\n",
      "147 Agregando campo: tree_9_leaf_2\n",
      "148 Agregando campo: tree_9_leaf_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149 Agregando campo: tree_9_leaf_4\n",
      "150 Agregando campo: tree_9_leaf_5\n",
      "151 Agregando campo: tree_9_leaf_6\n",
      "152 Agregando campo: tree_9_leaf_7\n",
      "153 Agregando campo: tree_9_leaf_8\n",
      "154 Agregando campo: tree_9_leaf_9\n",
      "155 Agregando campo: tree_9_leaf_10\n",
      "156 Agregando campo: tree_9_leaf_11\n",
      "157 Agregando campo: tree_9_leaf_12\n",
      "158 Agregando campo: tree_9_leaf_13\n",
      "159 Agregando campo: tree_9_leaf_14\n",
      "160 Agregando campo: tree_9_leaf_15\n",
      "161 Agregando campo: tree_10_leaf_0\n",
      "162 Agregando campo: tree_10_leaf_1\n",
      "163 Agregando campo: tree_10_leaf_2\n",
      "164 Agregando campo: tree_10_leaf_3\n",
      "165 Agregando campo: tree_10_leaf_4\n",
      "166 Agregando campo: tree_10_leaf_5\n",
      "167 Agregando campo: tree_10_leaf_6\n",
      "168 Agregando campo: tree_10_leaf_7\n",
      "169 Agregando campo: tree_10_leaf_8\n",
      "170 Agregando campo: tree_10_leaf_9\n",
      "171 Agregando campo: tree_10_leaf_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172 Agregando campo: tree_10_leaf_11\n",
      "173 Agregando campo: tree_10_leaf_12\n",
      "174 Agregando campo: tree_10_leaf_13\n",
      "175 Agregando campo: tree_10_leaf_14\n",
      "176 Agregando campo: tree_10_leaf_15\n",
      "177 Agregando campo: tree_11_leaf_0\n",
      "178 Agregando campo: tree_11_leaf_1\n",
      "179 Agregando campo: tree_11_leaf_2\n",
      "180 Agregando campo: tree_11_leaf_3\n",
      "181 Agregando campo: tree_11_leaf_4\n",
      "182 Agregando campo: tree_11_leaf_5\n",
      "183 Agregando campo: tree_11_leaf_6\n",
      "184 Agregando campo: tree_11_leaf_7\n",
      "185 Agregando campo: tree_11_leaf_8\n",
      "186 Agregando campo: tree_11_leaf_9\n",
      "187 Agregando campo: tree_11_leaf_10\n",
      "188 Agregando campo: tree_11_leaf_11\n",
      "189 Agregando campo: tree_11_leaf_12\n",
      "190 Agregando campo: tree_11_leaf_13\n",
      "191 Agregando campo: tree_11_leaf_14\n",
      "192 Agregando campo: tree_11_leaf_15\n",
      "193 Agregando campo: tree_12_leaf_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194 Agregando campo: tree_12_leaf_1\n",
      "195 Agregando campo: tree_12_leaf_2\n",
      "196 Agregando campo: tree_12_leaf_3\n",
      "197 Agregando campo: tree_12_leaf_4\n",
      "198 Agregando campo: tree_12_leaf_5\n",
      "199 Agregando campo: tree_12_leaf_6\n",
      "200 Agregando campo: tree_12_leaf_7\n",
      "201 Agregando campo: tree_12_leaf_8\n",
      "202 Agregando campo: tree_12_leaf_9\n",
      "203 Agregando campo: tree_12_leaf_10\n",
      "204 Agregando campo: tree_12_leaf_11\n",
      "205 Agregando campo: tree_12_leaf_12\n",
      "206 Agregando campo: tree_12_leaf_13\n",
      "207 Agregando campo: tree_12_leaf_14\n",
      "208 Agregando campo: tree_12_leaf_15\n",
      "209 Agregando campo: tree_13_leaf_0\n",
      "210 Agregando campo: tree_13_leaf_1\n",
      "211 Agregando campo: tree_13_leaf_2\n",
      "212 Agregando campo: tree_13_leaf_3\n",
      "213 Agregando campo: tree_13_leaf_4\n",
      "214 Agregando campo: tree_13_leaf_5\n",
      "215 Agregando campo: tree_13_leaf_6\n",
      "216 Agregando campo: tree_13_leaf_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217 Agregando campo: tree_13_leaf_8\n",
      "218 Agregando campo: tree_13_leaf_9\n",
      "219 Agregando campo: tree_13_leaf_10\n",
      "220 Agregando campo: tree_13_leaf_11\n",
      "221 Agregando campo: tree_13_leaf_12\n",
      "222 Agregando campo: tree_13_leaf_13\n",
      "223 Agregando campo: tree_13_leaf_14\n",
      "224 Agregando campo: tree_13_leaf_15\n",
      "225 Agregando campo: tree_14_leaf_0\n",
      "226 Agregando campo: tree_14_leaf_1\n",
      "227 Agregando campo: tree_14_leaf_2\n",
      "228 Agregando campo: tree_14_leaf_3\n",
      "229 Agregando campo: tree_14_leaf_4\n",
      "230 Agregando campo: tree_14_leaf_5\n",
      "231 Agregando campo: tree_14_leaf_6\n",
      "232 Agregando campo: tree_14_leaf_7\n",
      "233 Agregando campo: tree_14_leaf_8\n",
      "234 Agregando campo: tree_14_leaf_9\n",
      "235 Agregando campo: tree_14_leaf_10\n",
      "236 Agregando campo: tree_14_leaf_11\n",
      "237 Agregando campo: tree_14_leaf_12\n",
      "238 Agregando campo: tree_14_leaf_13\n",
      "239 Agregando campo: tree_14_leaf_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240 Agregando campo: tree_14_leaf_15\n",
      "241 Agregando campo: tree_15_leaf_0\n",
      "242 Agregando campo: tree_15_leaf_1\n",
      "243 Agregando campo: tree_15_leaf_2\n",
      "244 Agregando campo: tree_15_leaf_3\n",
      "245 Agregando campo: tree_15_leaf_4\n",
      "246 Agregando campo: tree_15_leaf_5\n",
      "247 Agregando campo: tree_15_leaf_6\n",
      "248 Agregando campo: tree_15_leaf_7\n",
      "249 Agregando campo: tree_15_leaf_8\n",
      "250 Agregando campo: tree_15_leaf_9\n",
      "251 Agregando campo: tree_15_leaf_10\n",
      "252 Agregando campo: tree_15_leaf_11\n",
      "253 Agregando campo: tree_15_leaf_12\n",
      "254 Agregando campo: tree_15_leaf_13\n",
      "255 Agregando campo: tree_15_leaf_14\n",
      "256 Agregando campo: tree_15_leaf_15\n",
      "257 Agregando campo: tree_16_leaf_0\n",
      "258 Agregando campo: tree_16_leaf_1\n",
      "259 Agregando campo: tree_16_leaf_2\n",
      "260 Agregando campo: tree_16_leaf_3\n",
      "261 Agregando campo: tree_16_leaf_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262 Agregando campo: tree_16_leaf_5\n",
      "263 Agregando campo: tree_16_leaf_6\n",
      "264 Agregando campo: tree_16_leaf_7\n",
      "265 Agregando campo: tree_16_leaf_8\n",
      "266 Agregando campo: tree_16_leaf_9\n",
      "267 Agregando campo: tree_16_leaf_10\n",
      "268 Agregando campo: tree_16_leaf_11\n",
      "269 Agregando campo: tree_16_leaf_12\n",
      "270 Agregando campo: tree_16_leaf_13\n",
      "271 Agregando campo: tree_16_leaf_14\n",
      "272 Agregando campo: tree_16_leaf_15\n",
      "273 Agregando campo: tree_17_leaf_0\n",
      "274 Agregando campo: tree_17_leaf_1\n",
      "275 Agregando campo: tree_17_leaf_2\n",
      "276 Agregando campo: tree_17_leaf_3\n",
      "277 Agregando campo: tree_17_leaf_4\n",
      "278 Agregando campo: tree_17_leaf_5\n",
      "279 Agregando campo: tree_17_leaf_6\n",
      "280 Agregando campo: tree_17_leaf_7\n",
      "281 Agregando campo: tree_17_leaf_8\n",
      "282 Agregando campo: tree_17_leaf_9\n",
      "283 Agregando campo: tree_17_leaf_10\n",
      "284 Agregando campo: tree_17_leaf_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285 Agregando campo: tree_17_leaf_12\n",
      "286 Agregando campo: tree_17_leaf_13\n",
      "287 Agregando campo: tree_17_leaf_14\n",
      "288 Agregando campo: tree_17_leaf_15\n",
      "289 Agregando campo: tree_18_leaf_0\n",
      "290 Agregando campo: tree_18_leaf_1\n",
      "291 Agregando campo: tree_18_leaf_2\n",
      "292 Agregando campo: tree_18_leaf_3\n",
      "293 Agregando campo: tree_18_leaf_4\n",
      "294 Agregando campo: tree_18_leaf_5\n",
      "295 Agregando campo: tree_18_leaf_6\n",
      "296 Agregando campo: tree_18_leaf_7\n",
      "297 Agregando campo: tree_18_leaf_8\n",
      "298 Agregando campo: tree_18_leaf_9\n",
      "299 Agregando campo: tree_18_leaf_10\n",
      "300 Agregando campo: tree_18_leaf_11\n",
      "301 Agregando campo: tree_18_leaf_12\n",
      "302 Agregando campo: tree_18_leaf_13\n",
      "303 Agregando campo: tree_18_leaf_14\n",
      "304 Agregando campo: tree_18_leaf_15\n",
      "305 Agregando campo: tree_19_leaf_0\n",
      "306 Agregando campo: tree_19_leaf_1\n",
      "307 Agregando campo: tree_19_leaf_2\n",
      "308 Agregando campo: tree_19_leaf_3\n",
      "309 Agregando campo: tree_19_leaf_4\n",
      "310 Agregando campo: tree_19_leaf_5\n",
      "311 Agregando campo: tree_19_leaf_6\n",
      "312 Agregando campo: tree_19_leaf_7\n",
      "313 Agregando campo: tree_19_leaf_8\n",
      "314 Agregando campo: tree_19_leaf_9\n",
      "315 Agregando campo: tree_19_leaf_10\n",
      "316 Agregando campo: tree_19_leaf_11\n",
      "317 Agregando campo: tree_19_leaf_12\n",
      "318 Agregando campo: tree_19_leaf_13\n",
      "319 Agregando campo: tree_19_leaf_14\n",
      "320 Agregando campo: tree_19_leaf_15\n",
      "Nuevo shape: (375309, 1403)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_6873/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    }
   ],
   "source": [
    "# Crear el OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)  # sparse_output=False para obtener un array denso\n",
    "# Ajustar y transformar los índices de las hojas\n",
    "leaf_dummies = encoder.fit_transform(leaf_indices)\n",
    "print (f'Shape de leaf_dummies: {leaf_dummies.shape}')\n",
    "\n",
    "# Obtener nombres de las columnas para las variables dummy\n",
    "n_trees = leaf_indices.shape[1]\n",
    "print (f\"Cant de árboles: {n_trees}\")\n",
    "leaf_columns = [f'tree_{i}_leaf_{leaf}' for i in range(n_trees) for leaf in range(encoder.categories_[i].size)]\n",
    "\n",
    "# Convertir a DataFrame\n",
    "leaf_dummies_df = pd.DataFrame(leaf_dummies, columns=leaf_columns)\n",
    "data_extended=data_original.copy()\n",
    "num_var=0\n",
    "for campo in leaf_dummies_df.columns:\n",
    "  num_var+=1\n",
    "  print (f'{num_var} Agregando campo: {campo}')\n",
    "  data_extended[campo]=leaf_dummies_df[campo]\n",
    "print (f'Nuevo shape: {data_extended.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vh4qRFp5CC0c"
   },
   "source": [
    "## Ver resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1731377041776,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "5t1fBMN0CFae",
    "outputId": "05c2d89a-cfc7-4382-ffb4-caa6073d3981"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cant de variables originales: 1083\n",
      "Cant de variables tree: 320\n",
      "Cant de variables extended: 1403\n",
      "Archivo a grabar: k2_aumentada_conRF.parquet.gz\n"
     ]
    }
   ],
   "source": [
    "num_variables_originales=data_original.shape[1]\n",
    "num_variables_tree = len([col for col in data_extended.columns if col.startswith('tree')])\n",
    "num_variables_extended=data_extended.shape[1]\n",
    "print (f'Cant de variables originales: {num_variables_originales}')\n",
    "print (f'Cant de variables tree: {num_variables_tree}')\n",
    "print (f'Cant de variables extended: {num_variables_extended}')\n",
    "print(f'Archivo a grabar: {output_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3485,
     "status": "ok",
     "timestamp": 1731377045257,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "jxOtbLz5FIme",
    "outputId": "8e092365-f193-462f-df63-0a8c8d301a75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         20.0\n",
      "1         20.0\n",
      "2         20.0\n",
      "3         20.0\n",
      "4         20.0\n",
      "          ... \n",
      "375304    20.0\n",
      "375305    20.0\n",
      "375306    20.0\n",
      "375307    20.0\n",
      "375308    20.0\n",
      "Length: 375309, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Filtra las columnas que empiezan con 'tree'\n",
    "tree_columns = [col for col in data_extended.columns if col.startswith('tree')]\n",
    "\n",
    "# Calcula la suma para cada registro en estas columnas\n",
    "suma_tree = data_extended[tree_columns].sum(axis=1)\n",
    "\n",
    "# Muestra el resultado\n",
    "print(suma_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1731377045258,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "5ImxA-PGDzLn",
    "outputId": "8852b6bd-a734-4b68-e212-b26da8cd6c50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contabilización de la base Datos extendidos con RF\n",
      "\n",
      "\n",
      "Shape: (375309, 1403)\n",
      "\n",
      "\\ por mes: \n",
      "foto_mes\n",
      "202108    165442\n",
      "202104     18363\n",
      "202105     18352\n",
      "202106     18271\n",
      "202103     18169\n",
      "202102     17886\n",
      "202101     17481\n",
      "202012     17307\n",
      "202011     17097\n",
      "202010     16921\n",
      "202009     16771\n",
      "202007     16629\n",
      "202008     16620\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Filas por mes y clase: \n",
      "clase_ternaria  BAJA+1  BAJA+2  CONTINUA\n",
      "foto_mes                                \n",
      "202007             627     542     15460\n",
      "202008             544     472     15604\n",
      "202009             474     564     15733\n",
      "202010             565     488     15868\n",
      "202011             490     646     15961\n",
      "202012             649     634     16024\n",
      "202101             635     785     16061\n",
      "202102             785    1017     16084\n",
      "202103            1020     981     16168\n",
      "202104             982    1189     16192\n",
      "202105            1189     911     16252\n",
      "202106             908    1074     16289\n",
      "202108          165442       0         0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "contabilizar(data_extended, 'Datos extendidos con RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AywiQ0pDLSRa"
   },
   "source": [
    "## Grabar salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1731377045258,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "Fms6Q4Srfh4a",
    "outputId": "f510076b-f62f-4c4c-c3f1-f21b76a80444"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numero_de_cliente                 int64\n",
       "foto_mes                          int64\n",
       "active_quarter                    int64\n",
       "cliente_vip                       int64\n",
       "internet                          int64\n",
       "                                 ...   \n",
       "Tarjeta_mpagominimo_n10_lag1    float64\n",
       "Tarjeta_mpagominimo_n10_lag2    float64\n",
       "clase_peso                      float64\n",
       "clase_binaria1                    int64\n",
       "clase_binaria2                    int64\n",
       "Length: 1083, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_original.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1731377045258,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "MZyR7PsvtIRJ",
    "outputId": "6e128b29-16b1-4a6c-eb0e-e5926b662b08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numero_de_cliente      int64\n",
       "foto_mes               int64\n",
       "active_quarter         int64\n",
       "cliente_vip            int64\n",
       "internet               int64\n",
       "                      ...   \n",
       "tree_19_leaf_11      float64\n",
       "tree_19_leaf_12      float64\n",
       "tree_19_leaf_13      float64\n",
       "tree_19_leaf_14      float64\n",
       "tree_19_leaf_15      float64\n",
       "Length: 1403, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_extended.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5fB9TXuWcrXH"
   },
   "outputs": [],
   "source": [
    "# Grabar el archivo\n",
    "if output_file.endswith('.gz'):\n",
    "    data_extended.to_parquet(os.path.join(dataset_path, output_file), index=False, compression='gzip')\n",
    "else:\n",
    "    data_extended.to_parquet(os.path.join(dataset_path, output_file), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1y99QdDXDmcFW4jzy9fxXFIXVI-j89yXJ",
     "timestamp": 1729967288089
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
