{"cells":[{"cell_type":"markdown","metadata":{"id":"1Vd-Rfyik62j"},"source":["# Gradient Boosting Desicion Tree\n","\n","VER LOS VIDEOS DE STATQUEST\n","\n","En las clases anteriores, observamos cómo las mejoras en los algoritmos y las optimizaciones pueden generar avances significativos en la ganancia. Ya hemos logrado un progreso considerable con los modelos de Random Forest. Hoy, daremos un paso aún más grande al explorar los modelos que actualmente están obteniendo los mejores resultados en este tipo de dominios.\n","\n","## La idea de boosting\n","Los registros que producen error reciben un peso mayor para que se ponga más atención en resolverlos, y hecho en forma cíclica.\n","\n","## La diea de gradient_boosting\n","Es para targets con 0 y 1 a clasificar\n","Arranco con todas con un mismo peso (p.ej. 0.5). O se parte de la proporción del target.\n","Acá se trata de predecir la diferencia entre el target y la clase/peso que se le asignó, o sea el error. Para el siguiente árbol se le suman los valores predichos y se vuelve a calcular errores y predecirlos.\n","\n","\n","Antes que nada, carguemos el entorno de trabajo\n"]},{"cell_type":"markdown","metadata":{"id":"5QHee4ugltSo"},"source":["# Preparar"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":336,"status":"ok","timestamp":1727999293603,"user":{"displayName":"Jose Chelquer","userId":"09375279337890014087"},"user_tz":180},"id":"-y-fy2-glu5U"},"outputs":[],"source":["## Conectar a drive"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2141,"status":"ok","timestamp":1727999296079,"user":{"displayName":"Jose Chelquer","userId":"09375279337890014087"},"user_tz":180},"id":"noUu9nOh60ls","outputId":"4209c915-d1ec-4326-f8cb-689557febb5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"Tq58M1oylxcQ"},"source":["## Librerías"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3565,"status":"ok","timestamp":1727999299639,"user":{"displayName":"Jose Chelquer","userId":"09375279337890014087"},"user_tz":180},"id":"Vhhu79HVkwb5","outputId":"c0a83e3f-58b4-4096-e3c0-2d2a23e32851"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: optuna==3.6.1 in /usr/local/lib/python3.10/dist-packages (3.6.1)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna==3.6.1) (1.13.3)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna==3.6.1) (6.8.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna==3.6.1) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna==3.6.1) (24.1)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna==3.6.1) (2.0.35)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna==3.6.1) (4.66.5)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna==3.6.1) (6.0.2)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna==3.6.1) (1.3.5)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna==3.6.1) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna==3.6.1) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna==3.6.1) (2.1.5)\n"]}],"source":["#%pip install scikit-learn==1.3.2\n","#%pip install seaborn==0.13.1\n","#%pip install numpy==1.26.4\n","#%pip install matplotlib==3.7.1\n","#%pip install pandas==2.1.4\n","#%pip install lightgbm==4.4.0\n","%pip install optuna==3.6.1"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1727999299639,"user":{"displayName":"Jose Chelquer","userId":"09375279337890014087"},"user_tz":180},"id":"Cj-rL6xHlA2u"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.impute import SimpleImputer\n","\n","import lightgbm as lgb\n","\n","import optuna\n","from optuna.visualization import plot_optimization_history, plot_param_importances, plot_slice, plot_contour\n","\n","from time import time\n","\n","import pickle"]},{"cell_type":"markdown","metadata":{"id":"bkwpAJ8_l0v5"},"source":["## Leer datos"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1727999299639,"user":{"displayName":"Jose Chelquer","userId":"09375279337890014087"},"user_tz":180},"id":"8jGKjoN1lRho"},"outputs":[],"source":["base_path =  \"/content/drive/MyDrive/Data Science y similares/Maestría Data Mining Exactas/dmeyf/dmeyf2024/\"\n","#trabajo_path=base_path + 'TareasHogar/tp1/'\n","dataset_file = 'competencia_01_aumentada.csv'\n","#dataset_file='competencia_01_reducida.csv'\n","#dataset_file = 'competencia_01.csv'\n","\n","dataset_path = base_path + 'datasets/'\n","modelos_path = base_path + 'modelos/'\n","db_path = base_path + 'db/'\n","\n","ganancia_acierto = 273000\n","costo_estimulo = 7000\n","\n","mes_train_desde = 202104\n","mes_train_hasta = 202104\n","mes_test = 202106\n","\n","# agregue sus semillas\n","semillas = [111103,  111109, 111119, 112211, 111217]\n","semilla=semillas[2]\n"]},{"cell_type":"code","source":["data = pd.read_csv(dataset_path + dataset_file)\n","if 'clase_ternaria_num' in data.columns:\n","  data = data.drop(columns=['clase_ternaria_num'])"],"metadata":{"id":"Y6wt6RE4jmQd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9TrH9f1L5Umd"},"source":["Vamos a asignar pesos a las clases. En unos minutos explicaremos las razones detrás de esta decisión. Mientras tanto, pueden aprovechar el código para ajustar el peso de la clase **BAJA+2** según lo deseen.\n"]},{"cell_type":"markdown","metadata":{"id":"MNnckhMQl4QC"},"source":["## Recodificar clase ternaria"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AlYeDIBQP3-s"},"outputs":[],"source":["data['clase_peso'] = 1.0\n","\n","data.loc[data['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n","data.loc[data['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KV1meQ5cZ_Sl"},"outputs":[],"source":["data['clase_binaria1'] = 0\n","data['clase_binaria2'] = 0\n","data['clase_binaria1'] = np.where(data['clase_ternaria'] == 'BAJA+2', 1, 0)\n","data['clase_binaria2'] = np.where(data['clase_ternaria'] == 'CONTINUA', 0, 1)"]},{"cell_type":"markdown","metadata":{"id":"5AYJG0r16dW9"},"source":["Y trabajaremos como es habitual en las últimas clases, con **Febrero** para entrenar y **Abril** para medir, con el fin de realizar *backtesting*"]},{"cell_type":"markdown","metadata":{"id":"8dXqpYY6l_Jk"},"source":["## Preparar train y test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iDyeXHAuCKuT"},"outputs":[],"source":["train_data = data[(data['foto_mes'] >= mes_train_desde)&(data['foto_mes'] <= mes_train_hasta)]\n","test_data = data[data['foto_mes'] == mes_test]\n","\n","X_train = train_data.drop(['clase_ternaria','clase_peso', 'clase_binaria1','clase_binaria2'], axis=1)\n","y_train_binaria1 = train_data['clase_binaria1']\n","y_train_binaria2 = train_data['clase_binaria2']\n","w_train = train_data['clase_peso']\n","\n","X_test = test_data.drop(['clase_ternaria', 'clase_peso', 'clase_binaria1','clase_binaria2'], axis=1)\n","y_test_binaria1 = test_data['clase_binaria1']\n","y_test_class = test_data['clase_ternaria']\n","w_test = test_data['clase_peso']"]},{"cell_type":"markdown","metadata":{"id":"scpnp1HJ6wfO"},"source":["Y preparamos el *dataset* para poder usar el **rf** de una clase anterior."]},{"cell_type":"markdown","metadata":{"id":"k31eSe5zlTEk"},"source":["Comenzaremos explicando el funcionamiento del protagonista de esta clase: **LightGBM**. Primero, partiremos con una revisión de cómo funciona el algoritmo en el que se basa, **XGBoost**. Para una introducción completa, puedes consultar este\n","\n","https://xgboost.readthedocs.io/en/stable/tutorials/model.html.\n","\n","Aunque en la cátedra no somos grandes seguidores de Josh Starmer y su canal *StatQuest*, reconozco que sus series sobre *Gradient Boosting* y *XGBoost* son excelentes recursos. Aquí te dejamos los enlaces a esas dos series que realmente valen la pena:\n","\n","[Serie Gradient Boosting](https://www.youtube.com/watch?v=3CC4N4z3GJc&list=PLblh5JKOoLUJjeXUvUE0maghNuY2_5fY6)\n","\n","[Serie XGBoost](https://www.youtube.com/watch?v=OtD8wVaFm6E&list=PLblh5JKOoLULU0irPgs1SnKO6wqVjKUsQ)\n","\n","Finalmente, analizaremos las diferencias clave que ofrece **LightGBM** frente a XGBoost. Puedes explorar más sobre ello en este https://lightgbm.readthedocs.io/en/stable/Features.html.\n","\n","No olvides tener a mano la [documentación de LightGBM](https://lightgbm.readthedocs.io/)y la [lista completa de sus parámetros](https://lightgbm.readthedocs.io/en/latest/Parameters.html).\n","\n","Este es un algoritmo muy usado en el mercado, recomiendo dedicarle el tiempo necesario para aprenderlo bien."]},{"cell_type":"markdown","metadata":{"id":"UQ-3AgzL9ude"},"source":["Vamos a utilizar el algoritmo directamente, sin pasar por *scikit-learn*. Sin embargo, si algún alumno lo prefiere, puede optar por usar el *wrapper* de sklearn para este caso.\n","\n","Para evaluar la calidad del modelo, crearemos nuestra propia función de evaluación que calcule la ganancia. La razón de incluir los pesos es precisamente para poder implementar esta función de evaluación de manera adecuada. Al combinar las clases *BAJA+1* y *BAJA+2* en una sola, necesitamos una forma de diferenciarlas, y es aquí donde entra en juego el *weight*. Este parámetro nos permitirá distinguir entre ambas clases al momento de evaluarlas dentro del algoritmo.\n"]},{"cell_type":"markdown","metadata":{"id":"zpwsHC5dnyrb"},"source":["# Optimizar"]},{"cell_type":"markdown","metadata":{"id":"6_Wom70Ln4Aa"},"source":[" ## cáclulo de ganancias"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_FvDUXeatl66"},"outputs":[],"source":["# La función de evaluacion para Optuna SIEMPRE debe tener estos dos parámetros:\n","#  los datos predichos y los datos sobre los que se predijo, porque esto es lo que le manda\n","#  optuna\n","def lgb_gan_eval(y_pred, data):\n","    weight = data.get_weight()\n","    # Diferencia si eran BAJA+1 o BAJA+2\n","    ganancia = np.where(weight == 1.00002, ganancia_acierto, 0) - np.where(weight < 1.00002, costo_estimulo, 0)\n","    #Ordena ganancia según los índices ordenados de y_pred de mayor a menor\n","    ganancia = ganancia[np.argsort(y_pred)[::-1]] #: desde todo : hasta todo :-1 step hacia atrás\n","    # Ganancias acumuladas so far\n","    ganancia = np.cumsum(ganancia)\n","\n","    return 'gan_eval', np.max(ganancia) , True\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Qte_kOcU-7i3"},"source":["LGBM necesita su propio tipo de Datasets:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5dnWsRWgPnRr"},"outputs":[],"source":["train_data1 = lgb.Dataset(X_train, label=y_train_binaria1, weight=w_train)\n","train_data2 = lgb.Dataset(X_train, label=y_train_binaria2, weight=w_train)"]},{"cell_type":"markdown","metadata":{"id":"kl71a3xJofZp"},"source":["## Función objetivo para optuna"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bYMEnNFbkSoQ"},"outputs":[],"source":["def objective(trial):\n","\n","    num_leaves = trial.suggest_int('num_leaves', 8, 300),\n","    learning_rate = trial.suggest_float('learning_rate', 0.005, 0.3), # mas bajo, más iteraciones necesita\n","    min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 1, 1500),\n","    feature_fraction = trial.suggest_float('feature_fraction', 0.1, 1.0),\n","    bagging_fraction = trial.suggest_float('bagging_fraction', 0.1, 1.0),\n","\n","    # Hiperparámetros adicionales\n","    #lambda_l1 = trial.suggest_float('lambda_l1', 0.0, 10.0)\n","    #lambda_l2 = trial.suggest_float('lambda_l2', 0.0, 10.0)\n","    min_gain_to_split = trial.suggest_float('min_gain_to_split', 0.0, 1.0)\n","    #max_depth = trial.suggest_int('max_depth', -1, 50)\n","    #bagging_freq = trial.suggest_int('bagging_freq', 0, 10)\n","    #colsample_bytree = trial.suggest_float('colsample_bytree', 0.1, 1.0)\n","    #early_stopping_rounds = trial.suggest_int('early_stopping_rounds', 10, 100)\n","\n","    params = {\n","        'objective': 'binary',\n","        'metric': 'custom',\n","        'boosting_type': 'gbdt',\n","        'first_metric_only': True,\n","        'boost_from_average': True,\n","        'feature_pre_filter': False,\n","        'max_bin': 31,\n","        'num_leaves': num_leaves,\n","        'learning_rate': learning_rate,\n","        'min_data_in_leaf': min_data_in_leaf,\n","        'feature_fraction': feature_fraction,\n","        'bagging_fraction': bagging_fraction,\n","        'seed': semilla,\n","        'verbose': -1,\n","\n","        # Hiperparámetros agregados\n","        'min_gain_to_split': min_gain_to_split,\n","        #'max_depth': max_depth,\n","        #'lambda_l1': lambda_l1,\n","        #'lambda_l2': lambda_l2,\n","        #'bagging_freq': bagging_freq,\n","        #'colsample_bytree': colsample_bytree,\n","        #'early_stopping_rounds': early_stopping_rounds,\n","\n","    }\n","    train_data = lgb.Dataset(X_train,\n","                              label=y_train_binaria2, # eligir la clase\n","                              weight=w_train)\n","    cv_results = lgb.cv(\n","        params,\n","        train_data,\n","        num_boost_round=200, # modificar, subit y subir... y descomentar la línea inferior. Subirlo muchísimo.\n","        #early_stopping_rounds= int(50 + 5 / learning_rate),         # Si subimos mucho el num_boost_round (más árboles), podemos hacer que termine por aquí. Es cant de rondas sin superar\n","        # aquí la función sabe por sí misma que tiene que usar como parámetros las predicciones y los datos\n","        feval=lgb_gan_eval,\n","        stratified=True,\n","        nfold=5,              #no lo muestra en el log pero lo está haciendo\n","        seed=semillas[1]\n","    )\n","    max_gan = max(cv_results['valid gan_eval-mean'])\n","    best_iter = cv_results['valid gan_eval-mean'].index(max_gan) + 1\n","\n","    # Guardamos cual es la mejor iteración del modelo\n","    trial.set_user_attr(\"best_iter\", best_iter)\n","\n","    return max_gan * 5        # Son 5 k-folds... parece que es por eso.\n"]},{"cell_type":"markdown","metadata":{"id":"BkK8xhV6olh1"},"source":["## Optuna"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8-Y2Ta25onAU"},"outputs":[],"source":["storage_name = \"sqlite:///\" + db_path + \"optimization_lgbm.db\"\n","study_name = \"lgbm_muy_ampliada\"\n","\n","# Crea el estudio\n","\n","# Si quiero recomenzar, desmarcar la siguiente línea\n","#optuna.delete_study(study_name=study_name, storage=storage_name)\n","study = optuna.create_study(\n","    direction=\"maximize\",\n","    study_name=study_name,\n","    storage=storage_name,\n","    load_if_exists=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AMrT22K0u9JF"},"outputs":[],"source":["#study.optimize(objective, n_trials=1) # subir subir\n","study.optimize(objective, n_trials=300) # subir subir"]},{"cell_type":"code","source":[],"metadata":{"id":"7jG5bnQSP-oZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ia2vN07FEasX"},"source":["Analizamos los resultados as usual"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fH4ybQgYx7Xf"},"outputs":[],"source":["optuna.visualization.plot_optimization_history(study)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vOfm5DXAx8Rj"},"outputs":[],"source":["plot_param_importances(study)"]},{"cell_type":"markdown","metadata":{"id":"O0Z-r8QYEsNN"},"source":["El **learning rate** es un parámetro que tiene que ir acompañado por más árboles."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0U6CfznSx-gG"},"outputs":[],"source":["plot_slice(study)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XRqPgCD6yB_q"},"outputs":[],"source":["plot_contour(study)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wGHGdGcQ3m00"},"outputs":[],"source":["plot_contour(study, params=['num_leaves','min_data_in_leaf'] )"]},{"cell_type":"markdown","metadata":{"id":"HjgD6raVE6am"},"source":["Y finalmente tomamos el mejor modelo y lo entrenamos con la totalidad de los datos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aj79YyG0VwXi"},"outputs":[],"source":["best_iter = study.best_trial.user_attrs[\"best_iter\"]\n","print(f\"Mejor cantidad de árboles para el mejor model {best_iter}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bwyUriQksZAM"},"outputs":[],"source":["best_iter = study.best_trial.user_attrs[\"best_iter\"]\n","print(f\"Mejor cantidad de árboles para el mejor model {best_iter}\")\n","params = {\n","    'objective': 'binary',\n","    'boosting_type': 'gbdt',\n","    'first_metric_only': True,\n","    'boost_from_average': True,\n","    'feature_pre_filter': False,\n","    'max_bin': 31,\n","    'num_leaves': study.best_trial.params['num_leaves'],\n","    'learning_rate': study.best_trial.params['learning_rate'],\n","    'min_data_in_leaf': study.best_trial.params['min_data_in_leaf'],\n","    'feature_fraction': study.best_trial.params['feature_fraction'],\n","    'bagging_fraction': study.best_trial.params['bagging_fraction'],\n","    'min_gain_to_split': study.best_trial.params['min_gain_to_split'],\n"," #   'early_stopping_rounds': study.best_trial.params['early_stopping_rounds'],\n","\n","    'seed': semilla,\n","    'verbose': 0\n","}\n","\n","train_data = lgb.Dataset(X_train,\n","                          label=y_train_binaria2,\n","                          weight=w_train)\n","\n","model = lgb.train(params,\n","                  train_data,\n","                  num_boost_round=best_iter)\n"]},{"cell_type":"markdown","metadata":{"id":"iOyqa5mbFySM"},"source":["Observamos la variables más importantes para el modelo:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xUejb7eutd0i"},"outputs":[],"source":["lgb.plot_importance(model, figsize=(10, 20))\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"LkTH9daXF5tp"},"source":["Y si queremos tener las variables más importantes en forma de *Dataframe*:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l7ZObpkHtnUl"},"outputs":[],"source":["importances = model.feature_importance()\n","feature_names = X_train.columns.tolist()\n","importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n","importance_df = importance_df.sort_values('importance', ascending=False)\n","importance_df[importance_df['importance'] > 0]\n"]},{"cell_type":"markdown","metadata":{"id":"pwvqxqc_GB-C"},"source":["Para guardar el modelo para poder utilizarlo más adelante, no es necesario guardarlo como *pickle*, la librería nos permite guardarlo en formato texto"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0lWWxwHhs2gp"},"outputs":[],"source":["model.save_model(modelos_path + 'lgb_muy_ampliada_abril.txt')"]},{"cell_type":"markdown","metadata":{"id":"iHIUeAdsGOWv"},"source":["Y recuperar el mismo desde ese formato"]},{"cell_type":"markdown","source":[],"metadata":{"id":"SVIbYPAGrQfg"}},{"cell_type":"markdown","source":[],"metadata":{"id":"4FZ8zR-grQWV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"H12h5wP2s645"},"outputs":[],"source":["model = lgb.Booster(model_file=modelos_path + 'lgb_muy_ampliada_abril.txt')"]},{"cell_type":"markdown","metadata":{"id":"28TQpPlIGi6a"},"source":["Ahora vamos a entrenar en **Abril  marzo** y predecir en  **Junio**\n","\n","> Añadir blockquote\n","\n"]},{"cell_type":"markdown","metadata":{"id":"W69RHMXsBFy_"},"source":["# Entrenar en Abril"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o4Olph6tBJMx"},"outputs":[],"source":["train_data = lgb.Dataset(X_train,\n","                          label=y_train_binaria2,\n","                          weight=w_train)\n","\n","model = lgb.train(params,\n","                  train_data,\n","                  num_boost_round=best_iter)\n"]},{"cell_type":"markdown","metadata":{"id":"M4Pv1weBB9a5"},"source":["## Predecir en junio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RFyfJ3R1B_Dk"},"outputs":[],"source":["y_pred=model.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aeYHfKN20Kf-"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"2Aat38kYztkq"},"source":["## Tarea:\n","\n","1. **Generar Dataset**  \n","   - Utilice las técnicas de *feature engineering* vistas en las clases anteriores para generar un nuevo conjunto de datos.\n","   \n","2. **Optimización de LightGBM (LGBM)**  \n","   - Ajuste el modelo de LightGBM utilizando una mayor cantidad de árboles y realice una exploración más exhaustiva de los hiperparámetros para mejorar su rendimiento.\n","   \n","3. **Incluir Nuevos Parámetros en la Optimización**  \n","   - Revise la documentación de los parámetros de LightGBM. Evalúe la inclusión de otros parámetros en el proceso de optimización, y ajuste el modelo con estos nuevos parámetros.\n","   \n","4. **Selección del Mejor Modelo**  \n","   - Entre los cinco mejores modelos obtenidos en cada optimización, seleccione el que considere más adecuado para la competencia en Kaggle.\n","   - Documente las pruebas que realizó para seleccionar el mejor modelo. Justifique su decisión con métricas relevantes y análisis comparativos.\n","5. Escriba y comparta por **Zulip** una función que envíe prepare el dataset que es necesario enviar a **kaggle** con los N clientes con mayor probabilidad."]},{"cell_type":"markdown","metadata":{"id":"B_aIb6aWOH4y"},"source":["## Enviar a Kaggle\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Esyf5-8Nn49G"},"outputs":[],"source":["# Cargo el kaggle.json para poder conectarme\n","import os\n","import shutil\n","\n","# Mueve kaggle.json al directorio correcto\n","os.makedirs('/root/.kaggle', exist_ok=True)\n","kaggle_json_path=\"/content/drive/MyDrive/Data Science y similares/Maestría Data Mining Exactas\"\n","shutil.copy(f'{kaggle_json_path}/kaggle.json', '/root/.kaggle/kaggle.json')\n","os.chmod('/root/.kaggle/kaggle.json', 600)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rtvjdOzeZqXj"},"outputs":[],"source":["  # En y_pred está la predicción hecha sobre junio\n","  # En X_test los datos de junio sobre los que se hizo la predicción\n","\n","  # Obtengo el orden de prioridad para el envío\n","idx_deseables=np.argsort(y_pred)[::-1]\n","\n","\n","  # --------------- fijo los parámetros de envío ---------------------\n","min_envios=8500\n","max_envios=16000\n","cant_envios=10\n","  # ------------------------------------------------------------------\n","\n","for envios in np.linspace(min_envios, max_envios, cant_envios, dtype=int):\n","    print (f\"Enviando: {envios}\")\n","    # Notar que idx_deseables tiene índices de y_pred (de 0 al máximo de línes de y_pred)\n","\n","    # los primeros envíos irán con predicción 1 y el resto 0\n","    # idx_deseables contiene los índices de y_pred (no los originales!!) cuyas predicciones tienen los mejores valores, en orden desdendente\n","    # guardo en elegidos los índices de los datos correspondientes a los primeros :envios en idx\n","    elegidos=X_test.index[idx_deseables[:envios]]\n","\n","    # Creo clientes_kaggle sólo con el número de cliente de  X_test\n","    clientes_kaggle=X_test.loc[:, ['numero_de_cliente']].copy()\n","    clientes_kaggle['Predicted']=0    #default\n","    clientes_kaggle.loc[elegidos, 'Predicted'] = 1   # marco los \"enviados\"\n","\n","    if clientes_kaggle.shape != (164876, 2):\n","        raise ValueError(f\"El DataFrame 'clientes_enviados' no tiene la forma esperada. Forma actual: {clientes_elegidos.shape}\")\n","    else:\n","        print(\"La forma de 'clientes_enviados' es correcta.\")\n","\n","    # elijo el nombre para el archivo enviar, para llevar control\n","    # un mensaje para registrar\n","    # y me grabo el archivo que mando para tener control local\n","    version=31\n","    # Voy a mandar con un mensaje que incluya los parámetros usados y la cantidad de envíos\n","    mensaje=f\"lgbm muy aumentada semilla {semilla} {params} entrenado abril-marzo pred junio envios {envios}\"\n","    # Me gusta guardar los envíos que hago\n","    archivo=f\"k601_{str(version).zfill(3)}-{envios}.csv\"\n","    path_archivo=dataset_path+archivo\n","    clientes_kaggle.to_csv(path_archivo, index=False)\n","\n","    # Envío a la competencia\n","    competencia=\"dm-ey-f-2024-primera\"\n","    !kaggle competitions submit -c {competencia} -f '{path_archivo}' -m '{mensaje}'\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kKG4RDFQp4TZ"},"outputs":[],"source":["params_str = str(params)\n","\n","# Eliminar llaves {}, apóstrofes ' y dos puntos :\n","params_str = params_str.replace('{', '').replace('}', '').replace(\"'\", '').replace(':', '').replace(\",\",'')\n","params_str"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EKEiO4g3nToF"},"outputs":[],"source":["clientes_kaggle"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1FPTZRsOUhcKFfbgSYW76KzbknDeILOWx","timestamp":1726524912160}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}