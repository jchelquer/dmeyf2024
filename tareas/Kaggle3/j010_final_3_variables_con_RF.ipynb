{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_xvJXPhCkMA"
   },
   "source": [
    "# Título  Variables con RF\n",
    "## Autor: Jose Chelquer\n",
    "## Fecha de última modificación: 21/11/2024\n",
    "## Descripción:\n",
    "Agrega features corriendo RF con lgbm.\n",
    "Agrega variables por cada hoja del lgbm, indicando si la observación está o no ahi.\n",
    "\n",
    "Para entrenar y predecir, no usa las variables relacionadas con foto_mes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRTSvXdLHkpB"
   },
   "source": [
    "## Parámetros\n",
    "\n",
    "< Descripción de cada uno de los parámetros que utiliza el job >\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimento _pc_\n",
      "completo\n",
      "con preprocesamiento\n",
      "completo\n",
      "sin RF\n"
     ]
    }
   ],
   "source": [
    "prueba=False                     # temporario. Volver a false\n",
    "\n",
    "\n",
    "experimento=\"_pc_\"                        # \n",
    "\n",
    "tipo_registros=experimento[0]            # '_'completo s sampleado\n",
    "con_preprocesamiento = experimento[1]    # p con preprocesamiento  '_' sin preprocesamiento\n",
    "tipo_featuring=experimento[2]            # _: 155 base  s: simple    c: completo\n",
    "rf=experimento[3]                        # _: sin RF   r: con RF\n",
    "\n",
    "dict_tipo_registros={'_': 'completo', 's': 'sampleado'}\n",
    "dict_con_preprocesamiento={'_': 'sin preprocesamiento', 'p':'con preprocesamiento'}\n",
    "dict_tipo_featuring={'_': 'base', 's':' simple', 'c': 'completo'}\n",
    "dict_rf={'_': 'sin RF', 'f':' con RF'}\n",
    "\n",
    "print (f'Experimento {experimento}')\n",
    "print (dict_tipo_registros[tipo_registros])\n",
    "print (dict_con_preprocesamiento[con_preprocesamiento])\n",
    "print (dict_tipo_featuring[tipo_featuring])\n",
    "print (dict_rf[rf])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yMU00Fl7IIfm"
   },
   "outputs": [],
   "source": [
    "# vm o local?\n",
    "vm=True\n",
    "if vm:\n",
    "  usar_gdrive=False\n",
    "else:\n",
    "  usar_gdrive=True      #se va a usar google dirve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KTHNlNBrPhX-"
   },
   "outputs": [],
   "source": [
    "semillas = [17,19,23,29,31]\n",
    "ganancia_acierto=273000\n",
    "costo_estimulo=7000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "61j56HBIKFeR"
   },
   "outputs": [],
   "source": [
    "# datos de entrenamiento\n",
    "if vm:\n",
    "  meses_entrenamiento=[202010, 202011, 202012]\n",
    "  submuestrear=False\n",
    "else:\n",
    "  meses_entrenamiento=[202101, 202102, 202103]\n",
    "  submuestrear=False\n",
    "\n",
    "grabar_importancias=False          # Se puede pedir que grabe las importancias de variables como resultado secundario\n",
    "importancias_file='importancias_rf.csv.gz'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sH5VivJSIM42"
   },
   "source": [
    "## Input\n",
    "\n",
    "< Archivos de datos (parquet.gz) con sus paths que van a consumirse por el job>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MEk4Fj7VIv7g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jose/buckets/b1/datasets/\n",
      "k3__pc_.parquet.gz\n"
     ]
    }
   ],
   "source": [
    "# El script se adapta a archivos .parquet o .parquet.gz\n",
    "if vm:\n",
    "  dataset_path = '/home/jose/buckets/b1/datasets/'\n",
    "  dataset_file=f'k3_{tipo_registros}{con_preprocesamiento}{tipo_featuring}_.parquet.gz'\n",
    "else:\n",
    "  dataset_path='/content/drive/MyDrive/Data Science y similares/Maestría Data Mining Exactas/dmeyf/dmeyf2024/datasets/'\n",
    "  dataset_file='k3_sample_parquet.gz'\n",
    "\n",
    "print (dataset_path)\n",
    "print (dataset_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQ6MUhENI0Ya"
   },
   "source": [
    "## Output\n",
    "\n",
    "< Archivos, bases de datos, modelos que va a generar el job>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZT3kxlkFIv4p"
   },
   "outputs": [],
   "source": [
    "# el script se adapta a datasets .parquet o .gz\n",
    "if vm:\n",
    "  output_file=f'k3_{tipo_registros}{con_preprocesamiento}{tipo_featuring}f.parquet.gz'\n",
    "else:\n",
    "  output_file='k3_sample.conRF.parquet.gz'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VrRYsZMowzEl"
   },
   "source": [
    "## Procesos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVe0GO1IJHtI"
   },
   "source": [
    "### Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3699,
     "status": "ok",
     "timestamp": 1731377015530,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "O2VG2xS_Ivq3",
    "outputId": "049bf30e-e1c8-45c9-8777-00ae64adadfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna==4.0 in /home/jose/.venv/lib/python3.12/site-packages (4.0.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/jose/.venv/lib/python3.12/site-packages (from optuna==4.0) (1.13.2)\n",
      "Requirement already satisfied: colorlog in /home/jose/.venv/lib/python3.12/site-packages (from optuna==4.0) (6.8.2)\n",
      "Requirement already satisfied: numpy in /home/jose/.venv/lib/python3.12/site-packages (from optuna==4.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jose/.venv/lib/python3.12/site-packages (from optuna==4.0) (24.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/jose/.venv/lib/python3.12/site-packages (from optuna==4.0) (2.0.35)\n",
      "Requirement already satisfied: tqdm in /home/jose/.venv/lib/python3.12/site-packages (from optuna==4.0) (4.66.5)\n",
      "Requirement already satisfied: PyYAML in /home/jose/.venv/lib/python3.12/site-packages (from optuna==4.0) (6.0.2)\n",
      "Requirement already satisfied: Mako in /home/jose/.venv/lib/python3.12/site-packages (from alembic>=1.5.0->optuna==4.0) (1.3.5)\n",
      "Requirement already satisfied: typing-extensions>=4 in /home/jose/.venv/lib/python3.12/site-packages (from alembic>=1.5.0->optuna==4.0) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/jose/.venv/lib/python3.12/site-packages (from sqlalchemy>=1.3.0->optuna==4.0) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/jose/.venv/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna==4.0) (2.1.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install optuna==3.6.1\n",
    "%pip install optuna==4.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LM2kY_WJj15"
   },
   "source": [
    "## Código del proceso\n",
    "\n",
    "< Todo el código a partir de aquí debe poder ejecutarse sin necesidad de parametrizar nada>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0X0atYk2Bqf"
   },
   "source": [
    "Instalamos, cargamos y seteamos el entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "sc7PN8Rw2Xz-"
   },
   "outputs": [],
   "source": [
    "#%pip install scikit-learn==1.3.2\n",
    "#%pip install seaborn==0.13.1\n",
    "#%pip install numpy==1.26.4\n",
    "#%pip install matplotlib==3.7.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vteA4xbLOv9m"
   },
   "source": [
    "## Gdrive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1918,
     "status": "ok",
     "timestamp": 1731377017442,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "SocMOWB6Ofpw",
    "outputId": "0f3af543-f708-446c-fc9d-279b235d53b3"
   },
   "outputs": [],
   "source": [
    "if usar_gdrive:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yVsD15O85ms"
   },
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/jose/.venv/lib/python3.12/site-packages (24.2)\n",
      "Collecting pip\n",
      "  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.2\n",
      "    Uninstalling pip-24.2:\n",
      "      Successfully uninstalled pip-24.2\n",
      "Successfully installed pip-24.3.1\n",
      "Requirement already satisfied: lightgbm in /home/jose/.venv/lib/python3.12/site-packages (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/jose/.venv/lib/python3.12/site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in /home/jose/.venv/lib/python3.12/site-packages (from lightgbm) (1.14.1)\n",
      "Requirement already satisfied: dask[dataframe] in /home/jose/.venv/lib/python3.12/site-packages (2024.9.0)\n",
      "Requirement already satisfied: click>=8.1 in /home/jose/.venv/lib/python3.12/site-packages (from dask[dataframe]) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /home/jose/.venv/lib/python3.12/site-packages (from dask[dataframe]) (3.0.0)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /home/jose/.venv/lib/python3.12/site-packages (from dask[dataframe]) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jose/.venv/lib/python3.12/site-packages (from dask[dataframe]) (24.1)\n",
      "Requirement already satisfied: partd>=1.4.0 in /home/jose/.venv/lib/python3.12/site-packages (from dask[dataframe]) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/jose/.venv/lib/python3.12/site-packages (from dask[dataframe]) (6.0.2)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /home/jose/.venv/lib/python3.12/site-packages (from dask[dataframe]) (0.12.1)\n",
      "Requirement already satisfied: pandas>=2.0 in /home/jose/.venv/lib/python3.12/site-packages (from dask[dataframe]) (2.2.3)\n",
      "Collecting dask-expr<1.2,>=1.1 (from dask[dataframe])\n",
      "  Downloading dask_expr-1.1.20-py3-none-any.whl.metadata (2.6 kB)\n",
      "INFO: pip is looking at multiple versions of dask-expr to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading dask_expr-1.1.19-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading dask_expr-1.1.18-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading dask_expr-1.1.16-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading dask_expr-1.1.15-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading dask_expr-1.1.14-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pyarrow>=14.0.1 in /home/jose/.venv/lib/python3.12/site-packages (from dask-expr<1.2,>=1.1->dask[dataframe]) (17.0.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/jose/.venv/lib/python3.12/site-packages (from pandas>=2.0->dask[dataframe]) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/jose/.venv/lib/python3.12/site-packages (from pandas>=2.0->dask[dataframe]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jose/.venv/lib/python3.12/site-packages (from pandas>=2.0->dask[dataframe]) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/jose/.venv/lib/python3.12/site-packages (from pandas>=2.0->dask[dataframe]) (2024.1)\n",
      "Requirement already satisfied: locket in /home/jose/.venv/lib/python3.12/site-packages (from partd>=1.4.0->dask[dataframe]) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/jose/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=2.0->dask[dataframe]) (1.16.0)\n",
      "Downloading dask_expr-1.1.14-py3-none-any.whl (242 kB)\n",
      "Installing collected packages: dask-expr\n",
      "Successfully installed dask-expr-1.1.14\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --upgrade lightgbm\n",
    "!pip install dask[dataframe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "x0IutZ5v4Pn5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n",
      "/home/jose/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import optuna\n",
    "from optuna.storages import JournalStorage\n",
    "from optuna.storages.journal import JournalFileBackend\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances, plot_slice, plot_contour\n",
    "\n",
    "from time import time\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import lightgbm as lgb\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1M-SwdFOykc"
   },
   "source": [
    "## Leer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "IbyPo4Dk4Mdh"
   },
   "outputs": [],
   "source": [
    "data_original = pd.read_parquet(os.path.join(dataset_path, dataset_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1731377029140,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "yK_UpTmCUmtv",
    "outputId": "ed4f9efa-529c-46ee-c617-b608a72b2d4b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\ '\n",
      "/tmp/ipykernel_2158/3529553369.py:4: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  print (f\"\\ por mes: \\n{df['foto_mes'].value_counts()}\\n\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contabilización de la base Datos Leídos\n",
      "\n",
      "\n",
      "Shape: (4901237, 1302)\n",
      "\n",
      "\\ por mes: \n",
      "foto_mes\n",
      "202109    165644\n",
      "202108    165442\n",
      "202107    165152\n",
      "202106    164876\n",
      "202105    164623\n",
      "202104    164090\n",
      "202103    163685\n",
      "202102    162646\n",
      "202101    162026\n",
      "202012    161526\n",
      "202011    160742\n",
      "202010    159731\n",
      "202009    158371\n",
      "202008    157058\n",
      "202007    155764\n",
      "202006    153757\n",
      "202005    151261\n",
      "202004    149872\n",
      "202003    149356\n",
      "202002    147109\n",
      "202001    143966\n",
      "201912    140661\n",
      "201911    138667\n",
      "201910    136682\n",
      "201909    134314\n",
      "201908    132664\n",
      "201907    130724\n",
      "201906    129186\n",
      "201905    127659\n",
      "201904    126996\n",
      "201903    126436\n",
      "201902    125799\n",
      "201901    124752\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Filas por mes y clase: \n",
      "clase_ternaria  BAJA+1  BAJA+2  CONTINUA\n",
      "foto_mes                                \n",
      "201901             688     718    123346\n",
      "201902             720     688    124391\n",
      "201903             688     760    124988\n",
      "201904             759     579    125658\n",
      "201905             580     660    126419\n",
      "201906             662     608    127916\n",
      "201907             609     689    129426\n",
      "201908             683     552    131429\n",
      "201909             553     576    133185\n",
      "201910             583     624    135475\n",
      "201911             623     735    137309\n",
      "201912             734     598    139329\n",
      "202001             605     502    142859\n",
      "202002             508     185    146416\n",
      "202003             186     378    148792\n",
      "202004             377     533    148962\n",
      "202005             536     629    150096\n",
      "202006             632     624    152501\n",
      "202007             627     542    154595\n",
      "202008             544     472    156042\n",
      "202009             474     564    157333\n",
      "202010             565     488    158678\n",
      "202011             490     646    159606\n",
      "202012             649     634    160243\n",
      "202101             635     785    160606\n",
      "202102             785    1017    160844\n",
      "202103            1020     981    161684\n",
      "202104             982    1189    161919\n",
      "202105            1189     911    162523\n",
      "202106             908    1074    162894\n",
      "202107            1075    1294    162783\n",
      "202108            1296  164146         0\n",
      "202109          165644       0         0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def contabilizar(df, descripción):\n",
    "  print (f'\\nContabilización de la base {descripción}\\n')\n",
    "  print (f'\\nShape: {df.shape}\\n')\n",
    "  print (f\"\\ por mes: \\n{df['foto_mes'].value_counts()}\\n\")\n",
    "  print (f\"\\nFilas por mes y clase: \\n{pd.crosstab(df['foto_mes'], df['clase_ternaria'])}\\n\")\n",
    "contabilizar(data_original, 'Datos Leídos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNfgftZTBfx1"
   },
   "source": [
    "## Recodificar a clase binaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0kIbkfo2Bekp"
   },
   "outputs": [],
   "source": [
    "data_original['clase_peso'] = 1.0\n",
    "\n",
    "data_original.loc[data_original['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "data_original.loc[data_original['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "954BAsluBteG"
   },
   "outputs": [],
   "source": [
    "data_original['clase_binaria1'] = 0\n",
    "data_original['clase_binaria2'] = 0\n",
    "data_original['clase_binaria1'] = np.where(data_original['clase_ternaria'] == 'BAJA+2', 1, 0)\n",
    "data_original['clase_binaria2'] = np.where(data_original['clase_ternaria'] == 'CONTINUA', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1731377029640,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "UnYMoA1l4jJ3",
    "outputId": "96e56757-79c1-453b-9056-102989301b48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contabilización de la base Datos para hacer RF\n",
      "\n",
      "\n",
      "Shape: (481999, 1305)\n",
      "\n",
      "\\ por mes: \n",
      "foto_mes\n",
      "202012    161526\n",
      "202011    160742\n",
      "202010    159731\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Filas por mes y clase: \n",
      "clase_ternaria  BAJA+1  BAJA+2  CONTINUA\n",
      "foto_mes                                \n",
      "202010             565     488    158678\n",
      "202011             490     646    159606\n",
      "202012             649     634    160243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Elige los meses y balancea\n",
    "if meses_entrenamiento:\n",
    "  data = data_original[data_original['foto_mes'].isin(meses_entrenamiento)]\n",
    "else:\n",
    "  data = data_original.copy()\n",
    "# Elimina las variables asociadas a foto_mes\n",
    "cols_fotos=[col for col in data.columns if 'foto_mes_lag' in col]\n",
    "data=data.drop(columns=cols_fotos)\n",
    "\n",
    "#Submuestrear para balancear\n",
    "if submuestrear:\n",
    "  # Separar las clases\n",
    "  data_0 = data[data['clase_binaria2'] == 0]\n",
    "  data_1 = data[data['clase_binaria2'] == 1]\n",
    "  n_samples=min(len(data_0), len(data_1))\n",
    "\n",
    "  # Hacer un submuestreo de la clase mayoritaria\n",
    "  data_0 = resample(data_0,\n",
    "                    replace=False,  # No reemplace\n",
    "                    n_samples=n_samples,  # Igualar tamaño de la clase minoritaria\n",
    "                    random_state=123)  # Para reproducibilidad\n",
    "  data_1 = resample(data_1,\n",
    "                    replace=False,  # No reemplace\n",
    "                    n_samples=n_samples,  # Igualar tamaño de la clase minoritaria\n",
    "                    random_state=123)  # Para reproducibilidad\n",
    "\n",
    "  # Combinar clases balanceadas\n",
    "  data_balanced = pd.concat([data_0, data_1])\n",
    "\n",
    "  # Mezclar el DataFrame resultante\n",
    "  data = data_balanced.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "contabilizar (data, 'Datos para hacer RF')\n",
    "\n",
    "y = data['clase_binaria2']\n",
    "X=data.drop(['clase_ternaria','clase_peso', 'clase_binaria1','clase_binaria2'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKqHx1ZMO2Iu"
   },
   "source": [
    "## Función ganancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "TWHFFm431krP"
   },
   "outputs": [],
   "source": [
    "def rf_gan_eval(y_pred, data):\n",
    "    clase_ternaria = data.get_clase_ternaria()\n",
    "    # Diferencia si eran BAJA+1 o BAJA+2\n",
    "    ganancia = np.where(clase_ternaria == 'BAJA+2', ganancia_acierto, 0) - np.where(clase_ternaria !='BAJA+2', costo_estimulo, 0)\n",
    "    #Ordena ganancia según los índices ordenados de y_pred de mayor a menor\n",
    "    ganancia = ganancia[np.argsort(y_pred)[::-1]] #: desde todo : hasta todo :-1 step hacia atrás\n",
    "    # Ganancias acumuladas so far\n",
    "    ganancia = np.cumsum(ganancia)\n",
    "\n",
    "    return 'gan_eval', np.max(ganancia) , True\n",
    "\n",
    "def ganancia_prob(y_hat, y, prop=1, class_index=1, threshold=0.025):\n",
    "  @np.vectorize\n",
    "  def ganancia_row(predicted, actual, threshold=0.025):\n",
    "    return  (predicted >= threshold) * (ganancia_acierto if actual == \"BAJA+2\" else -costo_estimulo)\n",
    "\n",
    "  return ganancia_row(y_hat[:,class_index], y).sum() / prop\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQ0ZGmGAK89b"
   },
   "source": [
    "## Imputar NANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 301,
     "status": "ok",
     "timestamp": 1731377029927,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "Ge2QADE-ZYiA",
    "outputId": "c097eb1c-55c5-4883-ce6b-79b32f4c5d83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cant de Nans:numero_de_cliente                    0\n",
      "foto_mes                             0\n",
      "active_quarter                       0\n",
      "cliente_vip                          0\n",
      "internet                             0\n",
      "                                  ... \n",
      "Tarjeta_mpagosdolares_n10_lag2    9900\n",
      "Tarjeta_mconsumototal_n10_lag1    4664\n",
      "Tarjeta_mconsumototal_n10_lag2    9900\n",
      "Tarjeta_mpagominimo_n10_lag1      4664\n",
      "Tarjeta_mpagominimo_n10_lag2      9900\n",
      "Length: 1301, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (f'Cant de Nans:{X.isnull().sum()}')\n",
    "#imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "#if X.isnull().values.any():\n",
    "#  X = imp_mean.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6qHrBQeLCej"
   },
   "source": [
    "## Ajustar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1854,
     "status": "ok",
     "timestamp": 1731377031779,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "ExNBUAIFIjdW",
    "outputId": "fa5e29bf-6722-48c2-a34d-0748268c8af0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fiteando\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin del fit\n"
     ]
    }
   ],
   "source": [
    "# Cambio\n",
    "# Fitear el modelo con X e y\n",
    "model = lgb.LGBMClassifier(\n",
    "    # parametros que se pueden cambiar\n",
    "    num_iterations = 20,\n",
    "    num_leaves  = 16,\n",
    "    min_data_in_leaf = 1000,\n",
    "    feature_fraction_bynode  = 0.2,\n",
    "\n",
    "    # para que LightGBM emule Random Forest\n",
    "    boosting_type = \"rf\",\n",
    "    bagging_fraction = ( 1.0 - 1.0/exp(1.0) ),\n",
    "    bagging_freq = 1,\n",
    "    feature_fraction = 1,\n",
    "\n",
    "    # genericos de LightGBM\n",
    "    max_bin = 31,\n",
    "    objective = \"binary\",\n",
    "    first_metric_only = True,\n",
    "    boost_from_average = True,\n",
    "    feature_pre_filter = False,\n",
    "    force_row_wise = True,\n",
    "    verbosity = -100,\n",
    "    max_depth = -1,\n",
    "    min_gain_to_split = 0.0,\n",
    "    min_sum_hessian_in_leaf = 0.001,\n",
    "    lambda_l1 = 0.0,\n",
    "    lambda_l2 = 0.0,\n",
    "\n",
    "    pos_bagging_fraction = 1.0,\n",
    "    neg_bagging_fraction = 1.0,\n",
    "    is_unbalance = True,\n",
    "    scale_pos_weight = 1.0,\n",
    "\n",
    "    drop_rate = 0.1,\n",
    "    max_drop = 50,\n",
    "    skip_drop = 0.5,\n",
    "\n",
    "    extra_trees = False\n",
    "  )\n",
    "print(\"Fiteando\")\n",
    "model.fit(X, y)\n",
    "print(\"Fin del fit\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1731377031780,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "jtbfCOrONos4",
    "outputId": "cca2d485-44b4-4839-f9d4-51b36d9c06a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   feature  importance\n",
      "50                                mpayroll          11\n",
      "838             avg_mcomisiones_otras_lag2          10\n",
      "1011  ratio_mcomisiones_mantenimiento_lag1          10\n",
      "1073         ratio_Visa_mlimitecompra_lag1          10\n",
      "777                   avg_mcomisiones_lag1           9\n",
      "368                           mpayroll_n10           9\n",
      "280                         ratio_mpayroll           9\n",
      "290        ratio_mcomisiones_mantenimiento           9\n",
      "836     avg_mcomisiones_mantenimiento_lag2           9\n",
      "778                   avg_mcomisiones_lag2           9\n",
      "49                            cpayroll_trx           8\n",
      "148                       mtarjeta_consumo           8\n",
      "1012  ratio_mcomisiones_mantenimiento_lag2           8\n",
      "203                  avg_mcomisiones_otras           7\n",
      "173                        avg_mcomisiones           7\n",
      "105                           ctrx_quarter           7\n",
      "147                 ctarjeta_transacciones           7\n",
      "835     avg_mcomisiones_mantenimiento_lag1           7\n",
      "321               ratio_Visa_mlimitecompra           6\n",
      "254                    avg_Tarjeta_mpagado           6\n"
     ]
    }
   ],
   "source": [
    "features = data.drop(['clase_ternaria','clase_peso', 'clase_binaria1','clase_binaria2'], axis=1).columns\n",
    "importances = model.feature_importances_\n",
    "feat_importances = pd.DataFrame({'feature': features, 'importance': importances})\n",
    "feat_importances = feat_importances.sort_values('importance', ascending=False)\n",
    "print(feat_importances.head(20))\n",
    "\n",
    "if grabar_importancias:\n",
    "    if importancias_file.endswith('.gz'):\n",
    "      feat_importances.to_parquet(os.path.join(dataset_path,  importancias_file), index=False, compression='gzip')\n",
    "    else:\n",
    "      feat_importances.to_parquet(os.path.join(dataset_path,  importancias_file), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqOU5mkfZdns"
   },
   "source": [
    "## Crear variables RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "nNPyQlmB-BXO"
   },
   "outputs": [],
   "source": [
    "# Ahora, con todos los datos\n",
    "\n",
    "cols_fotos=[col for col in data_original.columns if 'foto_mes_lag' in col]\n",
    "data=data_original.drop(columns=cols_fotos)\n",
    "y_completo=data['clase_binaria2']\n",
    "X_completo=data.drop(['clase_ternaria','clase_peso', 'clase_binaria1','clase_binaria2'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1221,
     "status": "ok",
     "timestamp": 1731377033989,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "hi9ED3_bdG6Y",
    "outputId": "5ebd75f5-7938-424b-b70c-08b9fdf018cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4901237, 20)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener las hojas para cada observación\n",
    "leaf_indices = model.predict(X_completo, pred_leaf=True)\n",
    "leaf_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1731377033989,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "XEGrS6kQ7If9",
    "outputId": "b328e0e1-ee81-491b-88fc-c7e52e22c7ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boosting_type': 'rf', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': None, 'num_leaves': 16, 'objective': 'binary', 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'num_iterations': 20, 'min_data_in_leaf': 1000, 'feature_fraction_bynode': 0.2, 'bagging_fraction': 0.6321205588285577, 'bagging_freq': 1, 'feature_fraction': 1, 'max_bin': 31, 'first_metric_only': True, 'boost_from_average': True, 'feature_pre_filter': False, 'force_row_wise': True, 'verbosity': -100, 'min_gain_to_split': 0.0, 'min_sum_hessian_in_leaf': 0.001, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'pos_bagging_fraction': 1.0, 'neg_bagging_fraction': 1.0, 'is_unbalance': True, 'scale_pos_weight': 1.0, 'drop_rate': 0.1, 'max_drop': 50, 'skip_drop': 0.5, 'extra_trees': False}\n"
     ]
    }
   ],
   "source": [
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7789,
     "status": "ok",
     "timestamp": 1731377041775,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "DaU4Ik_wPlMK",
    "outputId": "b2de4750-41da-4615-d425-aa9508fba432"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de leaf_dummies: (4901237, 320)\n",
      "Cant de árboles: 20\n",
      "1 Agregando campo: tree_0_leaf_0\n",
      "2 Agregando campo: tree_0_leaf_1\n",
      "3 Agregando campo: tree_0_leaf_2\n",
      "4 Agregando campo: tree_0_leaf_3\n",
      "5 Agregando campo: tree_0_leaf_4\n",
      "6 Agregando campo: tree_0_leaf_5\n",
      "7 Agregando campo: tree_0_leaf_6\n",
      "8 Agregando campo: tree_0_leaf_7\n",
      "9 Agregando campo: tree_0_leaf_8\n",
      "10 Agregando campo: tree_0_leaf_9\n",
      "11 Agregando campo: tree_0_leaf_10\n",
      "12 Agregando campo: tree_0_leaf_11\n",
      "13 Agregando campo: tree_0_leaf_12\n",
      "14 Agregando campo: tree_0_leaf_13\n",
      "15 Agregando campo: tree_0_leaf_14\n",
      "16 Agregando campo: tree_0_leaf_15\n",
      "17 Agregando campo: tree_1_leaf_0\n",
      "18 Agregando campo: tree_1_leaf_1\n",
      "19 Agregando campo: tree_1_leaf_2\n",
      "20 Agregando campo: tree_1_leaf_3\n",
      "21 Agregando campo: tree_1_leaf_4\n",
      "22 Agregando campo: tree_1_leaf_5\n",
      "23 Agregando campo: tree_1_leaf_6\n",
      "24 Agregando campo: tree_1_leaf_7\n",
      "25 Agregando campo: tree_1_leaf_8\n",
      "26 Agregando campo: tree_1_leaf_9\n",
      "27 Agregando campo: tree_1_leaf_10\n",
      "28 Agregando campo: tree_1_leaf_11\n",
      "29 Agregando campo: tree_1_leaf_12\n",
      "30 Agregando campo: tree_1_leaf_13\n",
      "31 Agregando campo: tree_1_leaf_14\n",
      "32 Agregando campo: tree_1_leaf_15\n",
      "33 Agregando campo: tree_2_leaf_0\n",
      "34 Agregando campo: tree_2_leaf_1\n",
      "35 Agregando campo: tree_2_leaf_2\n",
      "36 Agregando campo: tree_2_leaf_3\n",
      "37 Agregando campo: tree_2_leaf_4\n",
      "38 Agregando campo: tree_2_leaf_5\n",
      "39 Agregando campo: tree_2_leaf_6\n",
      "40 Agregando campo: tree_2_leaf_7\n",
      "41 Agregando campo: tree_2_leaf_8\n",
      "42 Agregando campo: tree_2_leaf_9\n",
      "43 Agregando campo: tree_2_leaf_10\n",
      "44 Agregando campo: tree_2_leaf_11\n",
      "45 Agregando campo: tree_2_leaf_12\n",
      "46 Agregando campo: tree_2_leaf_13\n",
      "47 Agregando campo: tree_2_leaf_14\n",
      "48 Agregando campo: tree_2_leaf_15\n",
      "49 Agregando campo: tree_3_leaf_0\n",
      "50 Agregando campo: tree_3_leaf_1\n",
      "51 Agregando campo: tree_3_leaf_2\n",
      "52 Agregando campo: tree_3_leaf_3\n",
      "53 Agregando campo: tree_3_leaf_4\n",
      "54 Agregando campo: tree_3_leaf_5\n",
      "55 Agregando campo: tree_3_leaf_6\n",
      "56 Agregando campo: tree_3_leaf_7\n",
      "57 Agregando campo: tree_3_leaf_8\n",
      "58 Agregando campo: tree_3_leaf_9\n",
      "59 Agregando campo: tree_3_leaf_10\n",
      "60 Agregando campo: tree_3_leaf_11\n",
      "61 Agregando campo: tree_3_leaf_12\n",
      "62 Agregando campo: tree_3_leaf_13\n",
      "63 Agregando campo: tree_3_leaf_14\n",
      "64 Agregando campo: tree_3_leaf_15\n",
      "65 Agregando campo: tree_4_leaf_0\n",
      "66 Agregando campo: tree_4_leaf_1\n",
      "67 Agregando campo: tree_4_leaf_2\n",
      "68 Agregando campo: tree_4_leaf_3\n",
      "69 Agregando campo: tree_4_leaf_4\n",
      "70 Agregando campo: tree_4_leaf_5\n",
      "71 Agregando campo: tree_4_leaf_6\n",
      "72 Agregando campo: tree_4_leaf_7\n",
      "73 Agregando campo: tree_4_leaf_8\n",
      "74 Agregando campo: tree_4_leaf_9\n",
      "75 Agregando campo: tree_4_leaf_10\n",
      "76 Agregando campo: tree_4_leaf_11\n",
      "77 Agregando campo: tree_4_leaf_12\n",
      "78 Agregando campo: tree_4_leaf_13\n",
      "79 Agregando campo: tree_4_leaf_14\n",
      "80 Agregando campo: tree_4_leaf_15\n",
      "81 Agregando campo: tree_5_leaf_0\n",
      "82 Agregando campo: tree_5_leaf_1\n",
      "83 Agregando campo: tree_5_leaf_2\n",
      "84 Agregando campo: tree_5_leaf_3\n",
      "85 Agregando campo: tree_5_leaf_4\n",
      "86 Agregando campo: tree_5_leaf_5\n",
      "87 Agregando campo: tree_5_leaf_6\n",
      "88 Agregando campo: tree_5_leaf_7\n",
      "89 Agregando campo: tree_5_leaf_8\n",
      "90 Agregando campo: tree_5_leaf_9\n",
      "91 Agregando campo: tree_5_leaf_10\n",
      "92 Agregando campo: tree_5_leaf_11\n",
      "93 Agregando campo: tree_5_leaf_12\n",
      "94 Agregando campo: tree_5_leaf_13\n",
      "95 Agregando campo: tree_5_leaf_14\n",
      "96 Agregando campo: tree_5_leaf_15\n",
      "97 Agregando campo: tree_6_leaf_0\n",
      "98 Agregando campo: tree_6_leaf_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 Agregando campo: tree_6_leaf_2\n",
      "100 Agregando campo: tree_6_leaf_3\n",
      "101 Agregando campo: tree_6_leaf_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 Agregando campo: tree_6_leaf_5\n",
      "103 Agregando campo: tree_6_leaf_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 Agregando campo: tree_6_leaf_7\n",
      "105 Agregando campo: tree_6_leaf_8\n",
      "106 Agregando campo: tree_6_leaf_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 Agregando campo: tree_6_leaf_10\n",
      "108 Agregando campo: tree_6_leaf_11\n",
      "109 Agregando campo: tree_6_leaf_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 Agregando campo: tree_6_leaf_13\n",
      "111 Agregando campo: tree_6_leaf_14\n",
      "112 Agregando campo: tree_6_leaf_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113 Agregando campo: tree_7_leaf_0\n",
      "114 Agregando campo: tree_7_leaf_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 Agregando campo: tree_7_leaf_2\n",
      "116 Agregando campo: tree_7_leaf_3\n",
      "117 Agregando campo: tree_7_leaf_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118 Agregando campo: tree_7_leaf_5\n",
      "119 Agregando campo: tree_7_leaf_6\n",
      "120 Agregando campo: tree_7_leaf_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 Agregando campo: tree_7_leaf_8\n",
      "122 Agregando campo: tree_7_leaf_9\n",
      "123 Agregando campo: tree_7_leaf_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124 Agregando campo: tree_7_leaf_11\n",
      "125 Agregando campo: tree_7_leaf_12\n",
      "126 Agregando campo: tree_7_leaf_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 Agregando campo: tree_7_leaf_14\n",
      "128 Agregando campo: tree_7_leaf_15\n",
      "129 Agregando campo: tree_8_leaf_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 Agregando campo: tree_8_leaf_1\n",
      "131 Agregando campo: tree_8_leaf_2\n",
      "132 Agregando campo: tree_8_leaf_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133 Agregando campo: tree_8_leaf_4\n",
      "134 Agregando campo: tree_8_leaf_5\n",
      "135 Agregando campo: tree_8_leaf_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136 Agregando campo: tree_8_leaf_7\n",
      "137 Agregando campo: tree_8_leaf_8\n",
      "138 Agregando campo: tree_8_leaf_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 Agregando campo: tree_8_leaf_10\n",
      "140 Agregando campo: tree_8_leaf_11\n",
      "141 Agregando campo: tree_8_leaf_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142 Agregando campo: tree_8_leaf_13\n",
      "143 Agregando campo: tree_8_leaf_14\n",
      "144 Agregando campo: tree_8_leaf_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145 Agregando campo: tree_9_leaf_0\n",
      "146 Agregando campo: tree_9_leaf_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147 Agregando campo: tree_9_leaf_2\n",
      "148 Agregando campo: tree_9_leaf_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149 Agregando campo: tree_9_leaf_4\n",
      "150 Agregando campo: tree_9_leaf_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151 Agregando campo: tree_9_leaf_6\n",
      "152 Agregando campo: tree_9_leaf_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 Agregando campo: tree_9_leaf_8\n",
      "154 Agregando campo: tree_9_leaf_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 Agregando campo: tree_9_leaf_10\n",
      "156 Agregando campo: tree_9_leaf_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157 Agregando campo: tree_9_leaf_12\n",
      "158 Agregando campo: tree_9_leaf_13\n",
      "159 Agregando campo: tree_9_leaf_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 Agregando campo: tree_9_leaf_15\n",
      "161 Agregando campo: tree_10_leaf_0\n",
      "162 Agregando campo: tree_10_leaf_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163 Agregando campo: tree_10_leaf_2\n",
      "164 Agregando campo: tree_10_leaf_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165 Agregando campo: tree_10_leaf_4\n",
      "166 Agregando campo: tree_10_leaf_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167 Agregando campo: tree_10_leaf_6\n",
      "168 Agregando campo: tree_10_leaf_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169 Agregando campo: tree_10_leaf_8\n",
      "170 Agregando campo: tree_10_leaf_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171 Agregando campo: tree_10_leaf_10\n",
      "172 Agregando campo: tree_10_leaf_11\n",
      "173 Agregando campo: tree_10_leaf_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174 Agregando campo: tree_10_leaf_13\n",
      "175 Agregando campo: tree_10_leaf_14\n",
      "176 Agregando campo: tree_10_leaf_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177 Agregando campo: tree_11_leaf_0\n",
      "178 Agregando campo: tree_11_leaf_1\n",
      "179 Agregando campo: tree_11_leaf_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 Agregando campo: tree_11_leaf_3\n",
      "181 Agregando campo: tree_11_leaf_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182 Agregando campo: tree_11_leaf_5\n",
      "183 Agregando campo: tree_11_leaf_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184 Agregando campo: tree_11_leaf_7\n",
      "185 Agregando campo: tree_11_leaf_8\n",
      "186 Agregando campo: tree_11_leaf_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187 Agregando campo: tree_11_leaf_10\n",
      "188 Agregando campo: tree_11_leaf_11\n",
      "189 Agregando campo: tree_11_leaf_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190 Agregando campo: tree_11_leaf_13\n",
      "191 Agregando campo: tree_11_leaf_14\n",
      "192 Agregando campo: tree_11_leaf_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193 Agregando campo: tree_12_leaf_0\n",
      "194 Agregando campo: tree_12_leaf_1\n",
      "195 Agregando campo: tree_12_leaf_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196 Agregando campo: tree_12_leaf_3\n",
      "197 Agregando campo: tree_12_leaf_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198 Agregando campo: tree_12_leaf_5\n",
      "199 Agregando campo: tree_12_leaf_6\n",
      "200 Agregando campo: tree_12_leaf_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201 Agregando campo: tree_12_leaf_8\n",
      "202 Agregando campo: tree_12_leaf_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203 Agregando campo: tree_12_leaf_10\n",
      "204 Agregando campo: tree_12_leaf_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205 Agregando campo: tree_12_leaf_12\n",
      "206 Agregando campo: tree_12_leaf_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207 Agregando campo: tree_12_leaf_14\n",
      "208 Agregando campo: tree_12_leaf_15\n",
      "209 Agregando campo: tree_13_leaf_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210 Agregando campo: tree_13_leaf_1\n",
      "211 Agregando campo: tree_13_leaf_2\n",
      "212 Agregando campo: tree_13_leaf_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213 Agregando campo: tree_13_leaf_4\n",
      "214 Agregando campo: tree_13_leaf_5\n",
      "215 Agregando campo: tree_13_leaf_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216 Agregando campo: tree_13_leaf_7\n",
      "217 Agregando campo: tree_13_leaf_8\n",
      "218 Agregando campo: tree_13_leaf_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219 Agregando campo: tree_13_leaf_10\n",
      "220 Agregando campo: tree_13_leaf_11\n",
      "221 Agregando campo: tree_13_leaf_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222 Agregando campo: tree_13_leaf_13\n",
      "223 Agregando campo: tree_13_leaf_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224 Agregando campo: tree_13_leaf_15\n",
      "225 Agregando campo: tree_14_leaf_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226 Agregando campo: tree_14_leaf_1\n",
      "227 Agregando campo: tree_14_leaf_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228 Agregando campo: tree_14_leaf_3\n",
      "229 Agregando campo: tree_14_leaf_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230 Agregando campo: tree_14_leaf_5\n",
      "231 Agregando campo: tree_14_leaf_6\n",
      "232 Agregando campo: tree_14_leaf_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233 Agregando campo: tree_14_leaf_8\n",
      "234 Agregando campo: tree_14_leaf_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235 Agregando campo: tree_14_leaf_10\n",
      "236 Agregando campo: tree_14_leaf_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237 Agregando campo: tree_14_leaf_12\n",
      "238 Agregando campo: tree_14_leaf_13\n",
      "239 Agregando campo: tree_14_leaf_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240 Agregando campo: tree_14_leaf_15\n",
      "241 Agregando campo: tree_15_leaf_0\n",
      "242 Agregando campo: tree_15_leaf_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243 Agregando campo: tree_15_leaf_2\n",
      "244 Agregando campo: tree_15_leaf_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245 Agregando campo: tree_15_leaf_4\n",
      "246 Agregando campo: tree_15_leaf_5\n",
      "247 Agregando campo: tree_15_leaf_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248 Agregando campo: tree_15_leaf_7\n",
      "249 Agregando campo: tree_15_leaf_8\n",
      "250 Agregando campo: tree_15_leaf_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251 Agregando campo: tree_15_leaf_10\n",
      "252 Agregando campo: tree_15_leaf_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253 Agregando campo: tree_15_leaf_12\n",
      "254 Agregando campo: tree_15_leaf_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255 Agregando campo: tree_15_leaf_14\n",
      "256 Agregando campo: tree_15_leaf_15\n",
      "257 Agregando campo: tree_16_leaf_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258 Agregando campo: tree_16_leaf_1\n",
      "259 Agregando campo: tree_16_leaf_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260 Agregando campo: tree_16_leaf_3\n",
      "261 Agregando campo: tree_16_leaf_4\n",
      "262 Agregando campo: tree_16_leaf_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263 Agregando campo: tree_16_leaf_6\n",
      "264 Agregando campo: tree_16_leaf_7\n",
      "265 Agregando campo: tree_16_leaf_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266 Agregando campo: tree_16_leaf_9\n",
      "267 Agregando campo: tree_16_leaf_10\n",
      "268 Agregando campo: tree_16_leaf_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269 Agregando campo: tree_16_leaf_12\n",
      "270 Agregando campo: tree_16_leaf_13\n",
      "271 Agregando campo: tree_16_leaf_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272 Agregando campo: tree_16_leaf_15\n",
      "273 Agregando campo: tree_17_leaf_0\n",
      "274 Agregando campo: tree_17_leaf_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275 Agregando campo: tree_17_leaf_2\n",
      "276 Agregando campo: tree_17_leaf_3\n",
      "277 Agregando campo: tree_17_leaf_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278 Agregando campo: tree_17_leaf_5\n",
      "279 Agregando campo: tree_17_leaf_6\n",
      "280 Agregando campo: tree_17_leaf_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281 Agregando campo: tree_17_leaf_8\n",
      "282 Agregando campo: tree_17_leaf_9\n",
      "283 Agregando campo: tree_17_leaf_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284 Agregando campo: tree_17_leaf_11\n",
      "285 Agregando campo: tree_17_leaf_12\n",
      "286 Agregando campo: tree_17_leaf_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287 Agregando campo: tree_17_leaf_14\n",
      "288 Agregando campo: tree_17_leaf_15\n",
      "289 Agregando campo: tree_18_leaf_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290 Agregando campo: tree_18_leaf_1\n",
      "291 Agregando campo: tree_18_leaf_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292 Agregando campo: tree_18_leaf_3\n",
      "293 Agregando campo: tree_18_leaf_4\n",
      "294 Agregando campo: tree_18_leaf_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295 Agregando campo: tree_18_leaf_6\n",
      "296 Agregando campo: tree_18_leaf_7\n",
      "297 Agregando campo: tree_18_leaf_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298 Agregando campo: tree_18_leaf_9\n",
      "299 Agregando campo: tree_18_leaf_10\n",
      "300 Agregando campo: tree_18_leaf_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301 Agregando campo: tree_18_leaf_12\n",
      "302 Agregando campo: tree_18_leaf_13\n",
      "303 Agregando campo: tree_18_leaf_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304 Agregando campo: tree_18_leaf_15\n",
      "305 Agregando campo: tree_19_leaf_0\n",
      "306 Agregando campo: tree_19_leaf_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307 Agregando campo: tree_19_leaf_2\n",
      "308 Agregando campo: tree_19_leaf_3\n",
      "309 Agregando campo: tree_19_leaf_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310 Agregando campo: tree_19_leaf_5\n",
      "311 Agregando campo: tree_19_leaf_6\n",
      "312 Agregando campo: tree_19_leaf_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313 Agregando campo: tree_19_leaf_8\n",
      "314 Agregando campo: tree_19_leaf_9\n",
      "315 Agregando campo: tree_19_leaf_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316 Agregando campo: tree_19_leaf_11\n",
      "317 Agregando campo: tree_19_leaf_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n",
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318 Agregando campo: tree_19_leaf_13\n",
      "319 Agregando campo: tree_19_leaf_14\n",
      "320 Agregando campo: tree_19_leaf_15\n",
      "Nuevo shape: (4901237, 1625)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2158/1647941747.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data_extended[campo]=leaf_dummies_df[campo]\n"
     ]
    }
   ],
   "source": [
    "# Crear el OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)  # sparse_output=False para obtener un array denso\n",
    "# Ajustar y transformar los índices de las hojas\n",
    "leaf_dummies = encoder.fit_transform(leaf_indices)\n",
    "print (f'Shape de leaf_dummies: {leaf_dummies.shape}')\n",
    "\n",
    "# Obtener nombres de las columnas para las variables dummy\n",
    "n_trees = leaf_indices.shape[1]\n",
    "print (f\"Cant de árboles: {n_trees}\")\n",
    "leaf_columns = [f'tree_{i}_leaf_{leaf}' for i in range(n_trees) for leaf in range(encoder.categories_[i].size)]\n",
    "\n",
    "# Convertir a DataFrame\n",
    "leaf_dummies_df = pd.DataFrame(leaf_dummies, columns=leaf_columns)\n",
    "data_extended=data_original.copy()\n",
    "num_var=0\n",
    "for campo in leaf_dummies_df.columns:\n",
    "  num_var+=1\n",
    "  print (f'{num_var} Agregando campo: {campo}')\n",
    "  data_extended[campo]=leaf_dummies_df[campo]\n",
    "print (f'Nuevo shape: {data_extended.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vh4qRFp5CC0c"
   },
   "source": [
    "## Ver resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1731377041776,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "5t1fBMN0CFae",
    "outputId": "05c2d89a-cfc7-4382-ffb4-caa6073d3981"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cant de variables originales: 1305\n",
      "Cant de variables tree: 320\n",
      "Cant de variables extended: 1625\n",
      "Archivo a grabar: k3__pcf.parquet.gz\n"
     ]
    }
   ],
   "source": [
    "num_variables_originales=data_original.shape[1]\n",
    "num_variables_tree = len([col for col in data_extended.columns if col.startswith('tree')])\n",
    "num_variables_extended=data_extended.shape[1]\n",
    "print (f'Cant de variables originales: {num_variables_originales}')\n",
    "print (f'Cant de variables tree: {num_variables_tree}')\n",
    "print (f'Cant de variables extended: {num_variables_extended}')\n",
    "print(f'Archivo a grabar: {output_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3485,
     "status": "ok",
     "timestamp": 1731377045257,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "jxOtbLz5FIme",
    "outputId": "8e092365-f193-462f-df63-0a8c8d301a75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          20.0\n",
      "1          20.0\n",
      "2          20.0\n",
      "3          20.0\n",
      "4          20.0\n",
      "           ... \n",
      "4901232    20.0\n",
      "4901233    20.0\n",
      "4901234    20.0\n",
      "4901235    20.0\n",
      "4901236    20.0\n",
      "Length: 4901237, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Filtra las columnas que empiezan con 'tree'\n",
    "tree_columns = [col for col in data_extended.columns if col.startswith('tree')]\n",
    "\n",
    "# Calcula la suma para cada registro en estas columnas\n",
    "suma_tree = data_extended[tree_columns].sum(axis=1)\n",
    "\n",
    "# Muestra el resultado\n",
    "print(suma_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1731377045258,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "5ImxA-PGDzLn",
    "outputId": "8852b6bd-a734-4b68-e212-b26da8cd6c50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contabilización de la base Datos extendidos con RF\n",
      "\n",
      "\n",
      "Shape: (4901237, 1625)\n",
      "\n",
      "\\ por mes: \n",
      "foto_mes\n",
      "202109    165644\n",
      "202108    165442\n",
      "202107    165152\n",
      "202106    164876\n",
      "202105    164623\n",
      "202104    164090\n",
      "202103    163685\n",
      "202102    162646\n",
      "202101    162026\n",
      "202012    161526\n",
      "202011    160742\n",
      "202010    159731\n",
      "202009    158371\n",
      "202008    157058\n",
      "202007    155764\n",
      "202006    153757\n",
      "202005    151261\n",
      "202004    149872\n",
      "202003    149356\n",
      "202002    147109\n",
      "202001    143966\n",
      "201912    140661\n",
      "201911    138667\n",
      "201910    136682\n",
      "201909    134314\n",
      "201908    132664\n",
      "201907    130724\n",
      "201906    129186\n",
      "201905    127659\n",
      "201904    126996\n",
      "201903    126436\n",
      "201902    125799\n",
      "201901    124752\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Filas por mes y clase: \n",
      "clase_ternaria  BAJA+1  BAJA+2  CONTINUA\n",
      "foto_mes                                \n",
      "201901             688     718    123346\n",
      "201902             720     688    124391\n",
      "201903             688     760    124988\n",
      "201904             759     579    125658\n",
      "201905             580     660    126419\n",
      "201906             662     608    127916\n",
      "201907             609     689    129426\n",
      "201908             683     552    131429\n",
      "201909             553     576    133185\n",
      "201910             583     624    135475\n",
      "201911             623     735    137309\n",
      "201912             734     598    139329\n",
      "202001             605     502    142859\n",
      "202002             508     185    146416\n",
      "202003             186     378    148792\n",
      "202004             377     533    148962\n",
      "202005             536     629    150096\n",
      "202006             632     624    152501\n",
      "202007             627     542    154595\n",
      "202008             544     472    156042\n",
      "202009             474     564    157333\n",
      "202010             565     488    158678\n",
      "202011             490     646    159606\n",
      "202012             649     634    160243\n",
      "202101             635     785    160606\n",
      "202102             785    1017    160844\n",
      "202103            1020     981    161684\n",
      "202104             982    1189    161919\n",
      "202105            1189     911    162523\n",
      "202106             908    1074    162894\n",
      "202107            1075    1294    162783\n",
      "202108            1296  164146         0\n",
      "202109          165644       0         0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "contabilizar(data_extended, 'Datos extendidos con RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AywiQ0pDLSRa"
   },
   "source": [
    "## Grabar salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1731377045258,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "Fms6Q4Srfh4a",
    "outputId": "f510076b-f62f-4c4c-c3f1-f21b76a80444"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numero_de_cliente                 int64\n",
       "foto_mes                          int64\n",
       "active_quarter                    int64\n",
       "cliente_vip                       int64\n",
       "internet                          int64\n",
       "                                 ...   \n",
       "Tarjeta_mpagominimo_n10_lag1    float64\n",
       "Tarjeta_mpagominimo_n10_lag2    float64\n",
       "clase_peso                      float64\n",
       "clase_binaria1                    int64\n",
       "clase_binaria2                    int64\n",
       "Length: 1305, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_original.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1731377045258,
     "user": {
      "displayName": "Jose Chelquer",
      "userId": "09375279337890014087"
     },
     "user_tz": 180
    },
    "id": "MZyR7PsvtIRJ",
    "outputId": "6e128b29-16b1-4a6c-eb0e-e5926b662b08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numero_de_cliente      int64\n",
       "foto_mes               int64\n",
       "active_quarter         int64\n",
       "cliente_vip            int64\n",
       "internet               int64\n",
       "                      ...   \n",
       "tree_19_leaf_11      float64\n",
       "tree_19_leaf_12      float64\n",
       "tree_19_leaf_13      float64\n",
       "tree_19_leaf_14      float64\n",
       "tree_19_leaf_15      float64\n",
       "Length: 1625, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_extended.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "5fB9TXuWcrXH"
   },
   "outputs": [],
   "source": [
    "# Grabar el archivo\n",
    "if output_file.endswith('.gz'):\n",
    "    data_extended.to_parquet(os.path.join(dataset_path, output_file), index=False, compression='gzip')\n",
    "else:\n",
    "    data_extended.to_parquet(os.path.join(dataset_path, output_file), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k3__pcf.parquet.gz\n"
     ]
    }
   ],
   "source": [
    "print (output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1y99QdDXDmcFW4jzy9fxXFIXVI-j89yXJ",
     "timestamp": 1729967288089
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
